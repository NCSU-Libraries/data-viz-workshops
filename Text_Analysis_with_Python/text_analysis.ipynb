{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGRR3FVUVyQb"
   },
   "source": [
    "<h1 align=\"center\">Text Analysis with Python</h1>\n",
    "\n",
    "## Instructors\n",
    "- Scott Bailey \n",
    "- Vincent Tompkins\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "Develop practical knowledge of an end-to-end workflow for text analysis in Python using two specific libraries: spaCy and textacy.\n",
    "\n",
    "- Import data\n",
    "- Clean/preprocess text data\n",
    "- Analyze single documents\n",
    "- Analyze a full corpus\n",
    "\n",
    "\n",
    "## Topics\n",
    "\n",
    "- Document Tokenization\n",
    "- Part-of-Speech (POS) Tagging\n",
    "- Named-Entity Recognition (NER)\n",
    "- Corpus Analysis and Vectorization\n",
    "\n",
    "##  Setup\n",
    "\n",
    "Clicking the \"Open in Colab\" button you can see after opening the Github link above will create a new temporary copy of the notebook in the Google Colaboratory environment. If you then click the \"Copy to Drive\" button that appears in the menu bar, the notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Zoom etiquette\n",
    "\n",
    "Please make sure that your mic is muted during the workshop.\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "During the workshop, we have a second instructor who will be monitoring chat on Zoom. Please feel free to ask questions by chat throughout the workshop. Our second instructor will answer as able, and will aggregate questions with answers that might help everyone. \n",
    "\n",
    "At the end of each section of the workshop, the primary instructor will answer aggregated and new questions as time permits. If we aren't able to get to your question during the workshop, please follow up with us afterward. \n",
    "\n",
    "## Jupyter Notebooks and Google Colaboratory\n",
    "\n",
    "Jupyter notebooks are a way to write and run Python code in an interactive way. They're quickly becoming a standard way of putting together data, code, and written explanations or visualizations into a single document and sharing that. There are a lot of ways that you can run Jupyter notebooks, including just locally on your computer, but we've decided to use Google's Colaboratory notebook platform for this workshop.  Colaboratory is “a Google research project created to help disseminate machine learning education and research.”  If you would like to know more about Colaboratory in general, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
    "\n",
    "Using the Google Colaboratory platform allows us to focus on learning and writing Python in the workshop rather than on setting up Python, which can sometimes take a bit of extra work depending on platforms, operating systems, and other installed applications. If you'd like to install a Python distribution locally, though, we're happy to help. Feel free to drop by our walk-in consulting or schedule an appointment with us.\n",
    "\n",
    "https://go.ncsu.edu/dvs-request\n",
    "\n",
    "## Environment\n",
    "If you would prefer to use Anaconda or your own local installation of python or Jupyter Notebooks, for this workshop you will need an environment with the following packages installed and available:\n",
    "- `spacy`\n",
    "- `textacy`\n",
    "\n",
    "Please note that we will not have time during the workshop to support you with problems related to a local environment, and we do recommend using the Colaboratory notebooks if you are at all unsure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEFaMNm3VyQf"
   },
   "source": [
    "# Document-level Analysis with `spaCy`\n",
    "\n",
    "Let's start by learning how spaCy works, and using it to start analyzing a single textual document. We'll work with some sample data throughout, but talk through importing larger corpora later in the workshop. \n",
    "\n",
    "For now, we'll start with imports, setting up the model, and working with a short text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1u3OoHQVyQh"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRVkmEOvVyQq"
   },
   "source": [
    "spaCy uses pre-trained neural network models to process text. Here we're going to download and use a medium-sized English multi-task CNN, which has high accuracy for part of speech tagging, entity recognition, and includes word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3lrUP1cVyQs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from en_core_web_md==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (45.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_md==2.2.5) (4.42.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/csbaile3/projects/data-viz-workshops/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31NWduWIVyQz"
   },
   "outputs": [],
   "source": [
    "# Once we've installed the model, we can load it like any other Python library\n",
    "import en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VT2rin_fVyQ6"
   },
   "outputs": [],
   "source": [
    "# Load the language model\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQYz476fVyRA"
   },
   "outputs": [],
   "source": [
    "# From H.G. Well's A Short History of the World, Project Gutenberg \n",
    "text = \"\"\"Even under the Assyrian monarchs and especially under\n",
    "Sardanapalus, Babylon had been a scene of great intellectual\n",
    "activity.  {111} Sardanapalus, though an Assyrian, had been quite\n",
    "Babylon-ized.  He made a library, a library not of paper but of\n",
    "the clay tablets that were used for writing in Mesopotamia since\n",
    "early Sumerian days.  His collection has been unearthed and is\n",
    "perhaps the most precious store of historical material in the\n",
    "world.  The last of the Chaldean line of Babylonian monarchs,\n",
    "Nabonidus, had even keener literary tastes.  He patronized\n",
    "antiquarian researches, and when a date was worked out by his\n",
    "investigators for the accession of Sargon I he commemorated the\n",
    "fact by inscriptions.  But there were many signs of disunion in\n",
    "his empire, and he sought to centralize it by bringing a number of\n",
    "the various local gods to Babylon and setting up temples to them\n",
    "there.  This device was to be practised quite successfully by the\n",
    "Romans in later times, but in Babylon it roused the jealousy of\n",
    "the powerful priesthood of Bel Marduk, the dominant god of the\n",
    "Babylonians.  They cast about for a possible alternative to\n",
    "Nabonidus and found it in Cyrus the Persian, the ruler of the\n",
    "adjacent Median Empire.  Cyrus had already distinguished himself\n",
    "by conquering Croesus, the rich king of Lydia in Eastern Asia\n",
    "Minor.  {112} He came up against Babylon, there was a battle\n",
    "outside the walls, and the gates of the city were opened to him\n",
    "(538 B.C.).  His soldiers entered the city without fighting.  The\n",
    "crown prince Belshazzar, the son of Nabonidus, was feasting, the\n",
    "Bible relates, when a hand appeared and wrote in letters of fire\n",
    "upon the wall these mystical words: _\"Mene, Mene, Tekel,\n",
    "Upharsin,\"_ which was interpreted by the prophet Daniel, whom he\n",
    "summoned to read the riddle, as \"God has numbered thy kingdom and\n",
    "finished it; thou art weighed in the balance and found wanting and\n",
    "thy kingdom is given to the Medes and Persians.\"  Possibly the\n",
    "priests of Bel Marduk knew something about that writing on the\n",
    "wall.  Belshazzar was killed that night, says the Bible.\n",
    "Nabonidus was taken prisoner, and the occupation of the city was\n",
    "so peaceful that the services of Bel Marduk continued without\n",
    "intermission.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LR5v_iE3VyRG"
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9pYgwcqVyRL"
   },
   "source": [
    "Once we pass the text into the NLP model, spaCy processes the entire text and makes many features available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnkTWvuwVyRN"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "The doc created by spaCy immediately provides access to the word level tokens of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zg6EB7WeVyRR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even\n",
      "under\n",
      "the\n",
      "Assyrian\n",
      "monarchs\n",
      "and\n",
      "especially\n",
      "under\n",
      "\n",
      "\n",
      "Sardanapalus\n",
      ",\n",
      "Babylon\n",
      "had\n",
      "been\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:15]:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh2z0VkgVyRW"
   },
   "source": [
    "Each of these tokens has a number of properties, and we'll look a bit more closely at this in a minute when we think about preprocessing texts, but let's continue our quick tour. \n",
    "\n",
    "spaCy also automatically provides sentence level tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6Rr6LvXVyRY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even under the Assyrian monarchs and especially under\n",
      "Sardanapalus, Babylon had been a scene of great intellectual\n",
      "activity.  \n",
      "--\n",
      "\n",
      "{111} Sardanapalus, though an Assyrian, had been quite\n",
      "Babylon-ized.  \n",
      "--\n",
      "\n",
      "He made a library, a library not of paper but of\n",
      "\n",
      "--\n",
      "\n",
      "the clay tablets that were used for writing in Mesopotamia since\n",
      "\n",
      "--\n",
      "\n",
      "early Sumerian days.  \n",
      "--\n",
      "\n",
      "His collection has been unearthed and is\n",
      "perhaps the most precious store of historical material in the\n",
      "world.  \n",
      "--\n",
      "\n",
      "The last of the Chaldean line of Babylonian monarchs,\n",
      "Nabonidus, had even keener literary tastes.  \n",
      "--\n",
      "\n",
      "He patronized\n",
      "antiquarian researches, and when a date was worked out by his\n",
      "investigators for the accession of Sargon\n",
      "--\n",
      "\n",
      "I\n",
      "--\n",
      "\n",
      "he commemorated the\n",
      "fact by inscriptions.  \n",
      "--\n",
      "\n",
      "But there were many signs of disunion in\n",
      "his empire, and he sought to centralize it by bringing a number of\n",
      "the various local gods to Babylon and setting up temples to them\n",
      "there.  \n",
      "--\n",
      "\n",
      "This device was to be practised quite successfully by the\n",
      "Romans in later times, but in Babylon it roused the jealousy of\n",
      "the powerful priesthood of Bel Marduk, the dominant god of the\n",
      "Babylonians.  \n",
      "--\n",
      "\n",
      "They cast about for a possible alternative to\n",
      "Nabonidus and found it in Cyrus the Persian, the ruler of the\n",
      "adjacent Median Empire.  \n",
      "--\n",
      "\n",
      "Cyrus had already distinguished himself\n",
      "by conquering Croesus, the rich king of Lydia in Eastern Asia\n",
      "Minor.  \n",
      "--\n",
      "\n",
      "{112} He came up against Babylon, there was a battle\n",
      "outside the walls, and the gates of the city were opened to him\n",
      "(538 B.C.).  \n",
      "--\n",
      "\n",
      "His soldiers entered the city without fighting.  \n",
      "--\n",
      "\n",
      "The\n",
      "crown prince Belshazzar, the son of Nabonidus, was feasting, the\n",
      "Bible relates, when a hand appeared and wrote in letters of fire\n",
      "upon the wall these mystical words: _\"Mene, Mene, Tekel,\n",
      "Upharsin,\"\n",
      "--\n",
      "\n",
      "_ which was interpreted by the prophet Daniel, whom he\n",
      "summoned to read the riddle, as \"God has numbered thy kingdom and\n",
      "finished it; thou art weighed in the balance and found wanting\n",
      "--\n",
      "\n",
      "and\n",
      "thy kingdom is given to the Medes and Persians.\"  \n",
      "--\n",
      "\n",
      "Possibly the\n",
      "priests of Bel Marduk knew something about that writing on the\n",
      "wall.  \n",
      "--\n",
      "\n",
      "Belshazzar was killed that night, says the Bible.\n",
      "\n",
      "--\n",
      "\n",
      "Nabonidus was taken prisoner, and the occupation of the city was\n",
      "so peaceful that the services of Bel Marduk continued without\n",
      "intermission.\n",
      "--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent.text + \"\\n--\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcwG9tH9VyRd"
   },
   "source": [
    "We can collect both words and sentences into standard Python data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwnDSjL7VyRe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Even under the Assyrian monarchs and especially under\\nSardanapalus, Babylon had been a scene of great intellectual\\nactivity.  ',\n",
       " '{111} Sardanapalus, though an Assyrian, had been quite\\nBabylon-ized.  ',\n",
       " 'He made a library, a library not of paper but of\\n',\n",
       " 'the clay tablets that were used for writing in Mesopotamia since\\n',\n",
       " 'early Sumerian days.  ',\n",
       " 'His collection has been unearthed and is\\nperhaps the most precious store of historical material in the\\nworld.  ',\n",
       " 'The last of the Chaldean line of Babylonian monarchs,\\nNabonidus, had even keener literary tastes.  ',\n",
       " 'He patronized\\nantiquarian researches, and when a date was worked out by his\\ninvestigators for the accession of Sargon',\n",
       " 'I',\n",
       " 'he commemorated the\\nfact by inscriptions.  ',\n",
       " 'But there were many signs of disunion in\\nhis empire, and he sought to centralize it by bringing a number of\\nthe various local gods to Babylon and setting up temples to them\\nthere.  ',\n",
       " 'This device was to be practised quite successfully by the\\nRomans in later times, but in Babylon it roused the jealousy of\\nthe powerful priesthood of Bel Marduk, the dominant god of the\\nBabylonians.  ',\n",
       " 'They cast about for a possible alternative to\\nNabonidus and found it in Cyrus the Persian, the ruler of the\\nadjacent Median Empire.  ',\n",
       " 'Cyrus had already distinguished himself\\nby conquering Croesus, the rich king of Lydia in Eastern Asia\\nMinor.  ',\n",
       " '{112} He came up against Babylon, there was a battle\\noutside the walls, and the gates of the city were opened to him\\n(538 B.C.).  ',\n",
       " 'His soldiers entered the city without fighting.  ',\n",
       " 'The\\ncrown prince Belshazzar, the son of Nabonidus, was feasting, the\\nBible relates, when a hand appeared and wrote in letters of fire\\nupon the wall these mystical words: _\"Mene, Mene, Tekel,\\nUpharsin,\"',\n",
       " '_ which was interpreted by the prophet Daniel, whom he\\nsummoned to read the riddle, as \"God has numbered thy kingdom and\\nfinished it; thou art weighed in the balance and found wanting',\n",
       " 'and\\nthy kingdom is given to the Medes and Persians.\"  ',\n",
       " 'Possibly the\\npriests of Bel Marduk knew something about that writing on the\\nwall.  ',\n",
       " 'Belshazzar was killed that night, says the Bible.\\n',\n",
       " 'Nabonidus was taken prisoner, and the occupation of the city was\\nso peaceful that the services of Bel Marduk continued without\\nintermission.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [sent.text for sent in doc.sents]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVJF1L5PVyRi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Even',\n",
       " 'under',\n",
       " 'the',\n",
       " 'Assyrian',\n",
       " 'monarchs',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'under',\n",
       " '\\n',\n",
       " 'Sardanapalus',\n",
       " ',',\n",
       " 'Babylon',\n",
       " 'had',\n",
       " 'been',\n",
       " 'a',\n",
       " 'scene',\n",
       " 'of',\n",
       " 'great',\n",
       " 'intellectual',\n",
       " '\\n',\n",
       " 'activity',\n",
       " '.',\n",
       " ' ',\n",
       " '{',\n",
       " '111',\n",
       " '}',\n",
       " 'Sardanapalus',\n",
       " ',',\n",
       " 'though',\n",
       " 'an']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [token.text for token in doc]\n",
    "words[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xndApEFuVyRn"
   },
   "source": [
    "### Filtering Tokens\n",
    "\n",
    "Let's start with cleaning the text and counting to see what we can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSHaSQWqVyRo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even False\n",
      "under False\n",
      "the False\n",
      "Assyrian False\n",
      "monarchs False\n",
      "and False\n",
      "especially False\n",
      "under False\n",
      "\n",
      " False\n",
      "Sardanapalus False\n",
      "Babylon False\n",
      "had False\n",
      "been False\n",
      "a False\n",
      "scene False\n",
      "of False\n",
      "great False\n",
      "intellectual False\n",
      "\n",
      " False\n",
      "activity False\n"
     ]
    }
   ],
   "source": [
    "# One of the common things we do in text analysis is to remove punctuation\n",
    "no_punct = [token for token in doc if token.is_punct == False]\n",
    "for token in no_punct[:20]:\n",
    "  print(token.text, token.is_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K63rP_PJVyRs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even\n",
      "under\n",
      "the\n",
      "Assyrian\n",
      "monarchs\n",
      "and\n",
      "especially\n",
      "under\n",
      "Sardanapalus\n",
      "Babylon\n",
      "had\n",
      "been\n",
      "a\n",
      "scene\n",
      "of\n",
      "great\n",
      "intellectual\n",
      "activity\n",
      "111\n",
      "Sardanapalus\n",
      "though\n",
      "an\n",
      "Assyrian\n",
      "had\n",
      "been\n",
      "quite\n",
      "Babylon\n",
      "ized\n",
      "He\n",
      "made\n"
     ]
    }
   ],
   "source": [
    "# This has worked, but left in new line characters and spaces\n",
    "no_punct_or_space = [token for token in doc if token.is_punct == False and token.is_space == False]\n",
    "for token in no_punct_or_space[:30]:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHjzgbbgVyRw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even',\n",
       " 'under',\n",
       " 'the',\n",
       " 'assyrian',\n",
       " 'monarchs',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'under',\n",
       " 'sardanapalus',\n",
       " 'babylon',\n",
       " 'had',\n",
       " 'been',\n",
       " 'a',\n",
       " 'scene',\n",
       " 'of',\n",
       " 'great',\n",
       " 'intellectual',\n",
       " 'activity',\n",
       " 'sardanapalus',\n",
       " 'though',\n",
       " 'an',\n",
       " 'assyrian',\n",
       " 'had',\n",
       " 'been',\n",
       " 'quite',\n",
       " 'babylon',\n",
       " 'ized',\n",
       " 'he',\n",
       " 'made',\n",
       " 'a']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we also want to remove numbers, and lowercase everything\n",
    "lower_alpha = [token.lower_ for token in no_punct_or_space if token.is_alpha == True]\n",
    "lower_alpha[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbpLhAqnVyR1"
   },
   "source": [
    "One other common bit of preprocessing is to remove stopwords, that is, the common words in a language that don't convey the information that we are looking for in our analysis. For example, if we looked for the most common words in a text, we would want to remove stopwords so that we don't only get words such as 'a,' 'the,' and 'and.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STyEpj96VyR2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assyrian',\n",
       " 'monarchs',\n",
       " 'especially',\n",
       " 'sardanapalus',\n",
       " 'babylon',\n",
       " 'scene',\n",
       " 'great',\n",
       " 'intellectual',\n",
       " 'activity',\n",
       " 'sardanapalus',\n",
       " 'assyrian',\n",
       " 'babylon',\n",
       " 'ized',\n",
       " 'library',\n",
       " 'library',\n",
       " 'paper',\n",
       " 'clay',\n",
       " 'tablets',\n",
       " 'writing',\n",
       " 'mesopotamia',\n",
       " 'early',\n",
       " 'sumerian',\n",
       " 'days',\n",
       " 'collection',\n",
       " 'unearthed',\n",
       " 'precious',\n",
       " 'store',\n",
       " 'historical',\n",
       " 'material',\n",
       " 'world']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = [token.lower_ for token in no_punct_or_space if token.is_alpha == True and token.is_stop == False]\n",
    "clean[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWe736X7mwKF"
   },
   "source": [
    "For this piece, we've used spaCy's built in stopword list, which is used to create the property `is_stop` for each token. There's a good chance you would want to create custom stopwords lists though, especially if you're working with historical text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tP8b8upcmx5q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even',\n",
       " 'under',\n",
       " 'the',\n",
       " 'monarchs',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'under',\n",
       " '\\n',\n",
       " 'sardanapalus',\n",
       " ',',\n",
       " 'had',\n",
       " 'been',\n",
       " 'a',\n",
       " 'scene',\n",
       " 'of',\n",
       " 'great',\n",
       " 'intellectual',\n",
       " '\\n',\n",
       " 'activity',\n",
       " '.',\n",
       " ' ',\n",
       " '{',\n",
       " '111',\n",
       " '}',\n",
       " 'sardanapalus',\n",
       " ',',\n",
       " 'though',\n",
       " 'an',\n",
       " ',',\n",
       " 'had',\n",
       " 'been',\n",
       " 'quite',\n",
       " '\\n',\n",
       " '-',\n",
       " 'ized',\n",
       " '.',\n",
       " ' ',\n",
       " 'he',\n",
       " 'made',\n",
       " 'a',\n",
       " 'library',\n",
       " ',',\n",
       " 'a',\n",
       " 'library',\n",
       " 'not',\n",
       " 'of',\n",
       " 'paper',\n",
       " 'but',\n",
       " 'of',\n",
       " '\\n',\n",
       " 'the',\n",
       " 'clay',\n",
       " 'tablets',\n",
       " 'that',\n",
       " 'were',\n",
       " 'used',\n",
       " 'for',\n",
       " 'writing',\n",
       " 'in',\n",
       " 'mesopotamia',\n",
       " 'since',\n",
       " '\\n',\n",
       " 'early',\n",
       " 'sumerian',\n",
       " 'days',\n",
       " '.',\n",
       " ' ',\n",
       " 'his',\n",
       " 'collection',\n",
       " 'has',\n",
       " 'been',\n",
       " 'unearthed',\n",
       " 'and',\n",
       " 'is',\n",
       " '\\n',\n",
       " 'perhaps',\n",
       " 'the',\n",
       " 'most',\n",
       " 'precious',\n",
       " 'store',\n",
       " 'of',\n",
       " 'historical',\n",
       " 'material',\n",
       " 'in',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'world',\n",
       " '.',\n",
       " ' ',\n",
       " 'the',\n",
       " 'last',\n",
       " 'of',\n",
       " 'the',\n",
       " 'chaldean',\n",
       " 'line',\n",
       " 'of',\n",
       " 'babylonian',\n",
       " 'monarchs',\n",
       " ',',\n",
       " '\\n',\n",
       " 'nabonidus',\n",
       " ',',\n",
       " 'had',\n",
       " 'even',\n",
       " 'keener',\n",
       " 'literary',\n",
       " 'tastes',\n",
       " '.',\n",
       " ' ',\n",
       " 'he',\n",
       " 'patronized',\n",
       " '\\n',\n",
       " 'antiquarian',\n",
       " 'researches',\n",
       " ',',\n",
       " 'and',\n",
       " 'when',\n",
       " 'a',\n",
       " 'date',\n",
       " 'was',\n",
       " 'worked',\n",
       " 'out',\n",
       " 'by',\n",
       " 'his',\n",
       " '\\n',\n",
       " 'investigators',\n",
       " 'for',\n",
       " 'the',\n",
       " 'accession',\n",
       " 'of',\n",
       " 'sargon',\n",
       " 'i',\n",
       " 'he',\n",
       " 'commemorated',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'fact',\n",
       " 'by',\n",
       " 'inscriptions',\n",
       " '.',\n",
       " ' ',\n",
       " 'but',\n",
       " 'there',\n",
       " 'were',\n",
       " 'many',\n",
       " 'signs',\n",
       " 'of',\n",
       " 'disunion',\n",
       " 'in',\n",
       " '\\n',\n",
       " 'his',\n",
       " 'empire',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'sought',\n",
       " 'to',\n",
       " 'centralize',\n",
       " 'it',\n",
       " 'by',\n",
       " 'bringing',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " '\\n',\n",
       " 'the',\n",
       " 'various',\n",
       " 'local',\n",
       " 'gods',\n",
       " 'to',\n",
       " 'and',\n",
       " 'setting',\n",
       " 'up',\n",
       " 'temples',\n",
       " 'to',\n",
       " 'them',\n",
       " '\\n',\n",
       " 'there',\n",
       " '.',\n",
       " ' ',\n",
       " 'this',\n",
       " 'device',\n",
       " 'was',\n",
       " 'to',\n",
       " 'be',\n",
       " 'practised',\n",
       " 'quite',\n",
       " 'successfully',\n",
       " 'by',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'romans',\n",
       " 'in',\n",
       " 'later',\n",
       " 'times',\n",
       " ',',\n",
       " 'but',\n",
       " 'in',\n",
       " 'it',\n",
       " 'roused',\n",
       " 'the',\n",
       " 'jealousy',\n",
       " 'of',\n",
       " '\\n',\n",
       " 'the',\n",
       " 'powerful',\n",
       " 'priesthood',\n",
       " 'of',\n",
       " 'bel',\n",
       " 'marduk',\n",
       " ',',\n",
       " 'the',\n",
       " 'dominant',\n",
       " 'god',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'babylonians',\n",
       " '.',\n",
       " ' ',\n",
       " 'they',\n",
       " 'cast',\n",
       " 'about',\n",
       " 'for',\n",
       " 'a',\n",
       " 'possible',\n",
       " 'alternative',\n",
       " 'to',\n",
       " '\\n',\n",
       " 'nabonidus',\n",
       " 'and',\n",
       " 'found',\n",
       " 'it',\n",
       " 'in',\n",
       " 'cyrus',\n",
       " 'the',\n",
       " 'persian',\n",
       " ',',\n",
       " 'the',\n",
       " 'ruler',\n",
       " 'of',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'adjacent',\n",
       " 'median',\n",
       " 'empire',\n",
       " '.',\n",
       " ' ',\n",
       " 'cyrus',\n",
       " 'had',\n",
       " 'already',\n",
       " 'distinguished',\n",
       " 'himself',\n",
       " '\\n',\n",
       " 'by',\n",
       " 'conquering',\n",
       " 'croesus',\n",
       " ',',\n",
       " 'the',\n",
       " 'rich',\n",
       " 'king',\n",
       " 'of',\n",
       " 'lydia',\n",
       " 'in',\n",
       " 'eastern',\n",
       " 'asia',\n",
       " '\\n',\n",
       " 'minor',\n",
       " '.',\n",
       " ' ',\n",
       " '{',\n",
       " '112',\n",
       " '}',\n",
       " 'he',\n",
       " 'came',\n",
       " 'up',\n",
       " 'against',\n",
       " ',',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'battle',\n",
       " '\\n',\n",
       " 'outside',\n",
       " 'the',\n",
       " 'walls',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'the',\n",
       " 'city',\n",
       " 'were',\n",
       " 'opened',\n",
       " 'to',\n",
       " 'him',\n",
       " '\\n',\n",
       " '(',\n",
       " '538',\n",
       " 'b.c.',\n",
       " ')',\n",
       " '.',\n",
       " ' ',\n",
       " 'his',\n",
       " 'soldiers',\n",
       " 'entered',\n",
       " 'the',\n",
       " 'city',\n",
       " 'without',\n",
       " 'fighting',\n",
       " '.',\n",
       " ' ',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'belshazzar',\n",
       " ',',\n",
       " 'the',\n",
       " 'son',\n",
       " 'of',\n",
       " 'nabonidus',\n",
       " ',',\n",
       " 'was',\n",
       " 'feasting',\n",
       " ',',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'bible',\n",
       " 'relates',\n",
       " ',',\n",
       " 'when',\n",
       " 'a',\n",
       " 'hand',\n",
       " 'appeared',\n",
       " 'and',\n",
       " 'wrote',\n",
       " 'in',\n",
       " 'letters',\n",
       " 'of',\n",
       " 'fire',\n",
       " '\\n',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'wall',\n",
       " 'these',\n",
       " 'mystical',\n",
       " 'words',\n",
       " ':',\n",
       " '_',\n",
       " '\"',\n",
       " 'mene',\n",
       " ',',\n",
       " 'mene',\n",
       " ',',\n",
       " 'tekel',\n",
       " ',',\n",
       " '\\n',\n",
       " 'upharsin',\n",
       " ',',\n",
       " '\"',\n",
       " '_',\n",
       " 'which',\n",
       " 'was',\n",
       " 'interpreted',\n",
       " 'by',\n",
       " 'the',\n",
       " 'prophet',\n",
       " 'daniel',\n",
       " ',',\n",
       " 'whom',\n",
       " 'he',\n",
       " '\\n',\n",
       " 'summoned',\n",
       " 'to',\n",
       " 'read',\n",
       " 'the',\n",
       " 'riddle',\n",
       " ',',\n",
       " 'as',\n",
       " '\"',\n",
       " 'god',\n",
       " 'has',\n",
       " 'numbered',\n",
       " 'thy',\n",
       " 'kingdom',\n",
       " 'and',\n",
       " '\\n',\n",
       " 'finished',\n",
       " 'it',\n",
       " ';',\n",
       " 'thou',\n",
       " 'art',\n",
       " 'weighed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'balance',\n",
       " 'and',\n",
       " 'found',\n",
       " 'wanting',\n",
       " 'and',\n",
       " '\\n',\n",
       " 'thy',\n",
       " 'kingdom',\n",
       " 'is',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'medes',\n",
       " 'and',\n",
       " 'persians',\n",
       " '.',\n",
       " '\"',\n",
       " ' ',\n",
       " 'possibly',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'priests',\n",
       " 'of',\n",
       " 'bel',\n",
       " 'marduk',\n",
       " 'knew',\n",
       " 'something',\n",
       " 'about',\n",
       " 'that',\n",
       " 'writing',\n",
       " 'on',\n",
       " 'the',\n",
       " '\\n',\n",
       " 'wall',\n",
       " '.',\n",
       " ' ',\n",
       " 'belshazzar',\n",
       " 'was',\n",
       " 'killed',\n",
       " 'that',\n",
       " 'night',\n",
       " ',',\n",
       " 'says',\n",
       " 'the',\n",
       " 'bible',\n",
       " '.',\n",
       " '\\n',\n",
       " 'nabonidus',\n",
       " 'was',\n",
       " 'taken',\n",
       " 'prisoner',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'occupation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'city',\n",
       " 'was',\n",
       " '\\n',\n",
       " 'so',\n",
       " 'peaceful',\n",
       " 'that',\n",
       " 'the',\n",
       " 'services',\n",
       " 'of',\n",
       " 'bel',\n",
       " 'marduk',\n",
       " 'continued',\n",
       " 'without',\n",
       " '\\n',\n",
       " 'intermission',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll just pick a couple of words we know are in the example\n",
    "custom_stopwords = [\"assyrian\", \"babylon\"]\n",
    "\n",
    "custom_clean = [token.lower_ for token in doc if token.lower_ not in custom_stopwords]\n",
    "custom_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ENXxjBHVyR8"
   },
   "source": [
    "At this point, we have a list of lower-cased tokens that doesn't contain punctuation, white-space, numbers, or stopwords. Depending on our analysis, we may or may not want to do this much cleaning. But, it is good to understand how much we can do just with spaCy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSGJfxiaVyR-"
   },
   "source": [
    "### Counting Tokens\n",
    "\n",
    "Let's then look at what we can do now that we have groups of tokens at different lengths. We can start with just counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEFjnPPLVySA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in document:  477\n",
      "Number of tokens in cleaned document:  175\n",
      "Number of unique tokens in cleaned document:  147\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in document: \", len(doc))\n",
    "print(\"Number of tokens in cleaned document: \", len(clean))\n",
    "print(\"Number of unique tokens in cleaned document: \", len(set(clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6JRDl22VySL"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZwZ3En1VySY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 36),\n",
       " ('\\n', 35),\n",
       " (',', 26),\n",
       " ('of', 20),\n",
       " ('.', 16),\n",
       " (' ', 14),\n",
       " ('and', 13),\n",
       " ('in', 9),\n",
       " ('a', 8),\n",
       " ('was', 8),\n",
       " ('to', 8),\n",
       " ('he', 6),\n",
       " ('by', 6),\n",
       " ('babylon', 5),\n",
       " ('had', 4),\n",
       " ('that', 4),\n",
       " ('his', 4),\n",
       " ('nabonidus', 4),\n",
       " ('it', 4),\n",
       " ('\"', 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_counter = Counter([token.lower_ for token in doc])\n",
    "full_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIrMQFp6VySg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('babylon', 5),\n",
       " ('nabonidus', 4),\n",
       " ('bel', 3),\n",
       " ('marduk', 3),\n",
       " ('city', 3),\n",
       " ('assyrian', 2),\n",
       " ('monarchs', 2),\n",
       " ('sardanapalus', 2),\n",
       " ('library', 2),\n",
       " ('writing', 2),\n",
       " ('empire', 2),\n",
       " ('god', 2),\n",
       " ('found', 2),\n",
       " ('cyrus', 2),\n",
       " ('belshazzar', 2),\n",
       " ('bible', 2),\n",
       " ('wall', 2),\n",
       " ('mene', 2),\n",
       " ('thy', 2),\n",
       " ('kingdom', 2)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_counter = Counter(clean)\n",
    "cleaned_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NL9FAgJjVySu"
   },
   "source": [
    "**Question:** Why do we have to use a list comprehension for the non-clean doc while we can just pass a variable directly for the cleaned set of tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xRNYHP7wVySv"
   },
   "source": [
    "## Part-of-Speech Tagging\n",
    "\n",
    "Let's turn to the other aspects of the text that spaCy exposes for us. Depending on what questions we might have about the text, these will be more or less helpful. \n",
    "\n",
    "We'll start with parts of speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLVUUOT9VySw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even ADV\n",
      "under ADP\n",
      "the DET\n",
      "Assyrian ADJ\n",
      "monarchs NOUN\n",
      "and CCONJ\n",
      "especially ADV\n",
      "under ADP\n",
      "\n",
      " SPACE\n",
      "Sardanapalus PROPN\n",
      ", PUNCT\n",
      "Babylon PROPN\n",
      "had AUX\n",
      "been AUX\n",
      "a DET\n",
      "scene NOUN\n",
      "of ADP\n",
      "great ADJ\n",
      "intellectual ADJ\n",
      "\n",
      " SPACE\n",
      "activity NOUN\n",
      ". PUNCT\n",
      "  SPACE\n",
      "{ PUNCT\n",
      "111 NUM\n",
      "} PUNCT\n",
      "Sardanapalus PROPN\n",
      ", PUNCT\n",
      "though SCONJ\n",
      "an DET\n"
     ]
    }
   ],
   "source": [
    "# spaCy provides two levels of POS tagging. Here's the more general.\n",
    "for token in doc[:30]:\n",
    "  print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbB2eeMTVyS2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even RB\n",
      "under IN\n",
      "the DT\n",
      "Assyrian JJ\n",
      "monarchs NN\n",
      "and CC\n",
      "especially RB\n",
      "under IN\n",
      "\n",
      " _SP\n",
      "Sardanapalus NNP\n",
      ", ,\n",
      "Babylon NNP\n",
      "had VBD\n",
      "been VBN\n",
      "a DT\n",
      "scene NN\n",
      "of IN\n",
      "great JJ\n",
      "intellectual JJ\n",
      "\n",
      " _SP\n",
      "activity NN\n",
      ". .\n",
      "  _SP\n",
      "{ -LRB-\n",
      "111 CD\n",
      "} -RRB-\n",
      "Sardanapalus NNP\n",
      ", ,\n",
      "though IN\n",
      "an DT\n"
     ]
    }
   ],
   "source": [
    "# We also have the more specific Penn Treenbank tags.\n",
    "# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "for token in doc[:30]:\n",
    "  print(token.text, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H6X3cbcmVyS4"
   },
   "source": [
    "We can accumulate the groups of tokens by way of these in order understand distributions of parts of speech throughout the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVey8EXsVyS5"
   },
   "outputs": [],
   "source": [
    "nouns = [token for token in doc if token.pos_ == \"NOUN\"]\n",
    "verbs = [token for token in doc if token.pos_ == \"VERB\"]\n",
    "proper_nouns = [token for token in doc if token.pos_ == \"PROPN\"]\n",
    "adjectives = [token for token in doc if token.pos_ == \"ADJ\"]\n",
    "adverbs = [token for token in doc if token.pos_ == \"ADV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qp6pH7VjVyTC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nouns': 67, 'verbs': 39, 'proper_nouns': 47, 'adjectives': 24, 'adverbs': 14}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counts = {\n",
    "    \"nouns\": len(nouns),\n",
    "    \"verbs\": len(verbs),\n",
    "    \"proper_nouns\": len(proper_nouns),\n",
    "    \"adjectives\": len(adjectives),\n",
    "    \"adverbs\": len(adverbs) \n",
    "}\n",
    "\n",
    "pos_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_1y3C5LVyTP"
   },
   "source": [
    "spaCy also provides full dependency parsing, but we're going to leave that alone for the moment. We'll turn instead to named entity recognition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29Mqf_S0VyTR"
   },
   "source": [
    "## Named-Entity Recognition\n",
    "\n",
    "https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KodfOLmHVyTS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assyrian NORP\n",
      "Babylon ORG\n",
      "111 CARDINAL\n",
      "Sardanapalus NORP\n",
      "Assyrian NORP\n",
      "Babylon PRODUCT\n",
      "Mesopotamia GPE\n",
      "early Sumerian days DATE\n",
      "the\n",
      "world LOC\n",
      "Chaldean NORP\n",
      "Babylonian NORP\n",
      "Sargon PERSON\n",
      "Babylon WORK_OF_ART\n",
      "Romans NORP\n",
      "Babylon PRODUCT\n",
      "Bel Marduk PERSON\n",
      "Babylonians NORP\n",
      "Cyrus ORG\n",
      "Persian NORP\n",
      "the\n",
      "adjacent Median Empire ORG\n",
      "Croesus ORG\n",
      "Lydia GPE\n",
      "Eastern Asia LOC\n",
      "112 CARDINAL\n",
      "Babylon ORG\n",
      "538 CARDINAL\n",
      "B.C. GPE\n",
      "Belshazzar PERSON\n",
      "Nabonidus NORP\n",
      "Bible WORK_OF_ART\n",
      "_\"Mene, Mene, PERSON\n",
      "Tekel GPE\n",
      "Upharsin PERSON\n",
      "Daniel PERSON\n",
      "Medes PERSON\n",
      "Persians NORP\n",
      "Bel Marduk PERSON\n",
      "Belshazzar PERSON\n",
      "night TIME\n",
      "Bible WORK_OF_ART\n",
      "Nabonidus PERSON\n",
      "Bel Marduk PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "  print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGCSdUMAVyTa"
   },
   "source": [
    "What if we only care about geo-political entities or locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhIk-M0DVyTc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mesopotamia', 'GPE'),\n",
       " ('the\\nworld', 'LOC'),\n",
       " ('Lydia', 'GPE'),\n",
       " ('Eastern Asia', 'LOC'),\n",
       " ('B.C.', 'GPE'),\n",
       " ('Tekel', 'GPE')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_filtered = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]]\n",
    "ent_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buJBVUPQVyTe"
   },
   "source": [
    "### Visualizing Parses\n",
    "\n",
    "spaCy also has a nice built-in visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3Ra-HtPVyTf"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIO_FEoLVyTi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Even under the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Assyrian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " monarchs and especially under</br>Sardanapalus, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " had been a scene of great intellectual</br>activity.  {\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    111\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "} \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sardanapalus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", though an \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Assyrian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", had been quite</br>\n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "-ized.  He made a library, a library not of paper but of</br>the clay tablets that were used for writing in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mesopotamia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " since</br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    early Sumerian days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".  His collection has been unearthed and is</br>perhaps the most precious store of historical material in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the\n",
       "world\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".  The last of the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chaldean\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " line of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylonian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " monarchs,</br>Nabonidus, had even keener literary tastes.  He patronized</br>antiquarian researches, and when a date was worked out by his</br>investigators for the accession of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sargon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " I he commemorated the</br>fact by inscriptions.  But there were many signs of disunion in</br>his empire, and he sought to centralize it by bringing a number of</br>the various local gods to \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " and setting up temples to them</br>there.  This device was to be practised quite successfully by the</br>\n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Romans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " in later times, but in \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " it roused the jealousy of</br>the powerful priesthood of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bel Marduk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", the dominant god of the</br>\n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylonians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ".  They cast about for a possible alternative to</br>Nabonidus and found it in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cyrus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Persian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", the ruler of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the\n",
       "adjacent Median Empire\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".  Cyrus had already distinguished himself</br>by conquering \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Croesus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", the rich king of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lydia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Eastern Asia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</br>Minor.  {\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    112\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "} He came up against \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", there was a battle</br>outside the walls, and the gates of the city were opened to him</br>(\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    538\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    B.C.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ").  His soldiers entered the city without fighting.  The</br>crown prince \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Belshazzar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", the son of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nabonidus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", was feasting, the</br>\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " relates, when a hand appeared and wrote in letters of fire</br>upon the wall these mystical words: \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    _&quot;Mene, Mene,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tekel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ",</br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Upharsin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ",&quot;_ which was interpreted by the prophet \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Daniel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", whom he</br>summoned to read the riddle, as &quot;God has numbered thy kingdom and</br>finished it; thou art weighed in the balance and found wanting and</br>thy kingdom is given to the \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Medes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Persians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ".&quot;  Possibly the</br>priests of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bel Marduk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " knew something about that writing on the</br>wall.  \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Belshazzar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was killed that \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    night\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ", says the \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       ".</br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nabonidus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was taken prisoner, and the occupation of the city was</br>so peaceful that the services of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bel Marduk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " continued without\n",
       "intermission.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this visualizer to display the dependency parse of the doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1eb0833a598d460f9eb1e702abea9f1b-0\" class=\"displacy\" width=\"3725\" height=\"749.5\" direction=\"ltr\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Even</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">under</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Assyrian</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">monarchs</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">especially</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">under</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Sardanapalus,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Babylon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">had</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">been</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">scene</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">great</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">intellectual</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">activity.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\"> </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,527.0 195.0,527.0 195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-1\" stroke-width=\"2px\" d=\"M245,614.5 C245,2.0 2150.0,2.0 2150.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,616.5 L237,604.5 253,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-2\" stroke-width=\"2px\" d=\"M420,614.5 C420,439.5 725.0,439.5 725.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,616.5 L412,604.5 428,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-3\" stroke-width=\"2px\" d=\"M595,614.5 C595,527.0 720.0,527.0 720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,616.5 L587,604.5 603,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-4\" stroke-width=\"2px\" d=\"M245,614.5 C245,352.0 730.0,352.0 730.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730.0,616.5 L738.0,604.5 722.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-5\" stroke-width=\"2px\" d=\"M245,614.5 C245,264.5 910.0,264.5 910.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,616.5 L918.0,604.5 902.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-6\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,527.0 1245.0,527.0 1245.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,616.5 L1112,604.5 1128,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-7\" stroke-width=\"2px\" d=\"M245,614.5 C245,177.0 1265.0,177.0 1265.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,616.5 L1273.0,604.5 1257.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-8\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,527.0 1420.0,527.0 1420.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1420.0,616.5 L1428.0,604.5 1412.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-9\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,439.5 1600.0,439.5 1600.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600.0,616.5 L1608.0,604.5 1592.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-10\" stroke-width=\"2px\" d=\"M1820,614.5 C1820,439.5 2125.0,439.5 2125.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,616.5 L1812,604.5 1828,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-11\" stroke-width=\"2px\" d=\"M1995,614.5 C1995,527.0 2120.0,527.0 2120.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,616.5 L1987,604.5 2003,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-12\" stroke-width=\"2px\" d=\"M2345,614.5 C2345,527.0 2470.0,527.0 2470.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,616.5 L2337,604.5 2353,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-13\" stroke-width=\"2px\" d=\"M2170,614.5 C2170,439.5 2475.0,439.5 2475.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2475.0,616.5 L2483.0,604.5 2467.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-14\" stroke-width=\"2px\" d=\"M2520,614.5 C2520,527.0 2645.0,527.0 2645.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2645.0,616.5 L2653.0,604.5 2637.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-15\" stroke-width=\"2px\" d=\"M2870,614.5 C2870,352.0 3355.0,352.0 3355.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,616.5 L2862,604.5 2878,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-16\" stroke-width=\"2px\" d=\"M3045,614.5 C3045,439.5 3350.0,439.5 3350.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3045,616.5 L3037,604.5 3053,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-17\" stroke-width=\"2px\" d=\"M3045,614.5 C3045,527.0 3170.0,527.0 3170.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3170.0,616.5 L3178.0,604.5 3162.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-18\" stroke-width=\"2px\" d=\"M2170,614.5 C2170,89.5 3370.0,89.5 3370.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3370.0,616.5 L3378.0,604.5 3362.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1eb0833a598d460f9eb1e702abea9f1b-0-19\" stroke-width=\"2px\" d=\"M3395,614.5 C3395,527.0 3520.0,527.0 3520.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1eb0833a598d460f9eb1e702abea9f1b-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3520.0,616.5 L3528.0,604.5 3512.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_sent = next(doc.sents)\n",
    "displacy.render(single_sent, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VU5dIAnMiODg"
   },
   "source": [
    "### Activity\n",
    "\n",
    "Pick either a particular part of speech or a named entity type, and write code to determine the most common words of that type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mro3MhI-ieQk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3F5P7cbMVyTl"
   },
   "source": [
    "# Corpus-level Analysis with `textacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCwkgf9pVyTl"
   },
   "source": [
    "Let's shift to thinking about a whole corpus rather than a single document.\n",
    "\n",
    "In doing so, we could keep working with spaCy directly if the features that it exposes help us answer the research questions we are asking. \n",
    "\n",
    "Instead, though, we're going to take advantage of textacy, a library built on spaCy that adds features, including a sense of a Corpus and built in analytics on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp3AcJezVyTn"
   },
   "outputs": [],
   "source": [
    "!pip install textacy==0.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMqTW64-VyTp"
   },
   "source": [
    "## Generating Corpora\n",
    "\n",
    "We'll use some of the data that is included in textacy as our corpus. You could absolutely import data otherwise, whether through reading in plain text or xml files, or pulling text data and metadata from a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8HmDN36VyTq"
   },
   "outputs": [],
   "source": [
    "import textacy\n",
    "import textacy.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYKe7-BCVyTs"
   },
   "outputs": [],
   "source": [
    "# We'll work with some Supreme Court cases: https://chartbeat-labs.github.io/textacy/_modules/textacy/datasets/supreme_court.html\n",
    "data = textacy.datasets.SupremeCourt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xmidNbxVyTu"
   },
   "outputs": [],
   "source": [
    "data.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9X-twUBVyTw"
   },
   "source": [
    "What we have here is a collection of Supreme Court decisions, both full text and metadata. \n",
    "\n",
    "Let's look at a single one to see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHMbaig9VyTx"
   },
   "outputs": [],
   "source": [
    "single = list(data.texts(limit=1))[0]\n",
    "single[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4Xf3CkM9dJS"
   },
   "source": [
    "Let's go ahead and pull a full set of texts with metadata. To keep it a bit more manageable time-wise, we'll only collect 100 of the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZk5b7zxVyTz"
   },
   "outputs": [],
   "source": [
    "records = data.records(limit=100)\n",
    "\n",
    "# Records here is a generator - we can look at the first record by passing it to the next function.\n",
    "next(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TwurMgHVyT0"
   },
   "source": [
    "textacy includes the idea of a corpus, while spaCy only has an idea of a single documents, though you can compose documents in standard Python data structures. Every corpus takes some texts or text plus metadata, along with a language model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gdHIQAyVyT0"
   },
   "outputs": [],
   "source": [
    "corpus = textacy.Corpus(nlp, data=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_0YOC-kVyT3"
   },
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBnvE5ZJVyT7"
   },
   "outputs": [],
   "source": [
    "[doc._.preview for doc in corpus[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuBjFKQ4VyT8"
   },
   "source": [
    "We can see that the type of each item in the corpus is a `Doc` - this is effectively a spaCy doc with all of the calculated features. Textacy does give you some capacity to work with those features through it's API, and also exposes new features, such as ngrams and ranking algorithms for single documents. We'll come back to these once we work a bit at the corpus level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-DFWqESvVyT8"
   },
   "source": [
    "We can filter this corpus based on metadata once we make it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-CqNgQaVyUC"
   },
   "outputs": [],
   "source": [
    "# Here we'll find all the cases where the number of justices voting in the majority was greater than 6. \n",
    "recent = [doc for doc in corpus.get(lambda doc: doc._.meta[\"n_maj_votes\"] > 6)]\n",
    "len(recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4o5hy0pCVyUG"
   },
   "outputs": [],
   "source": [
    "recent[0]._.preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8YO2bgIVyUM"
   },
   "source": [
    "## Analyzing the Corpus\n",
    "\n",
    "Let's look at what we get out of the box from textacy once we've built a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wOMpBE0VyUM"
   },
   "outputs": [],
   "source": [
    "print(\"number of documents: \", corpus.n_docs)\n",
    "print(\"number of sentences: \", corpus.n_sents)\n",
    "print(\"number of tokens: \", corpus.n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiQQrx5SVyUO"
   },
   "outputs": [],
   "source": [
    "# We'll pass as_strings so that the results we look at will give us strings rather than unique ids.\n",
    "counts = corpus.word_counts(as_strings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWwr9r1fFOuE"
   },
   "source": [
    "Notice that, by default, the `word_counts` function is doing a certain amount of cleaning for you: https://chartbeat-labs.github.io/textacy/api_reference/lang_doc_corpus.html#textacy.corpus.Corpus.word_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blFXigFMVyUQ"
   },
   "outputs": [],
   "source": [
    "sorted(counts.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYx5VX51H8SF"
   },
   "source": [
    "For an explanation of `-PRON-`, see https://spacy.io/api/annotation#lemmatization. Basically it's spaCy's way of lemmatizing pronouns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELd2rxUZVyUU"
   },
   "outputs": [],
   "source": [
    "word_doc_counts = corpus.word_doc_counts(weighting=\"freq\", smooth_idf=True, filter_stops=True, as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wIIkImS2VyUW"
   },
   "outputs": [],
   "source": [
    "sorted(word_doc_counts.items(), key=lambda x:x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5r_AcIMVyUa"
   },
   "source": [
    "We should note that these are not tf-idf values, which are term frequencies for individual docs weighted by the inverse document frequency. This is a measure of the number of docs the words appear in weighted by inverse document frequency. We're still getting a sense of which words across the corpus and in the context of the corpus seem to have the most importance, if document frequency is a proxy for importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wx69GIqUdqtx"
   },
   "source": [
    "Textacy provides access to different algorithms that can be run on docs, such as TextRank for keyword extraction. We'll start by working on a single doc, and then look at how we might scale up to thinking about the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQCRD7WTeI1j"
   },
   "outputs": [],
   "source": [
    "import textacy.ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSwQ4Rw6dWaT"
   },
   "outputs": [],
   "source": [
    "key_terms_textrank = textacy.ke.textrank(corpus[4])\n",
    "key_terms_textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRyHfZekewCT"
   },
   "source": [
    "For comparison, we'll take a look at another algorithm, Yake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HWvJ8ube4Vc"
   },
   "outputs": [],
   "source": [
    "key_terms_yake = textacy.ke.yake(corpus[4])\n",
    "key_terms_yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OarUA-BMfmV7"
   },
   "source": [
    "Let's think about aggregating keywords over part of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXNpQrZafrzi"
   },
   "outputs": [],
   "source": [
    "key_terms_textrank_corpus = [textacy.ke.yake(doc) for doc in corpus[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XCA9CT4f5N5"
   },
   "outputs": [],
   "source": [
    "key_terms_textrank_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4EJrV3EgBcs"
   },
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in key_terms_textrank_corpus for item in sublist]\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have a flat list of tuples, but let's shift to a flat list of just the keys in order to \n",
    "# count the most common keys\n",
    "flat_list_keys = [k for k,v in flat_list]\n",
    "flat_list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3HHZLIXgawc"
   },
   "outputs": [],
   "source": [
    "keyword_counter = Counter(flat_list_keys)\n",
    "keyword_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P296E9nxhnQZ"
   },
   "source": [
    "### Activity:\n",
    "Let's combine a few different pieces. Try filtering the corpus on some metadata to construct a sub-corpus. Then use one of the textacy keyword algorithms to determine the most common keywords across your subcorpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_ZuOB3_h4Wn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nuk7s1yZlvVi"
   },
   "source": [
    "## Keyword in context\n",
    "\n",
    "One thing that researchers often find helpful in working with text is simply seeing keywords in context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxgjXFnRla1-"
   },
   "outputs": [],
   "source": [
    "for doc in corpus[:20]:\n",
    "  textacy.text_utils.KWIC(doc.text, \"agriculture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuSHX_2OVyUb"
   },
   "source": [
    "## Vectorization\n",
    "\n",
    "Let's continue with corpus level analysis by taking advantage of textacy's vectorizer class, which wraps functionality from scikit-learn. We could just work directly in scikit-learn, but it can be nice for mental overhead to learn one library and be able to do a great deal with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pFXy9VK7DXa"
   },
   "source": [
    "We'll create a vectorizer, sticking with the normal term frequency defaults but discarding words that appear in less than 3 documents or more than 95% of documents. We'll also limit our features to the top 500 words according to document frequency.This means our feature set, or columns, will have a higher degree of representation across the corpus. We could vectorize according to tf-idf as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LfE48GbVyUb"
   },
   "outputs": [],
   "source": [
    "import textacy.vsm\n",
    "\n",
    "vectorizer = textacy.vsm.Vectorizer(min_df=3, max_df=.95, max_n_terms=500)\n",
    "tokenized_corpus = (doc._.to_terms_list(ngrams=1, as_strings=True,\n",
    "                                        filter_punct=True, \n",
    "                                        filter_stops=True, \n",
    "                                        filter_nums=True \n",
    "                                        ) for doc in corpus)\n",
    "dtm = vectorizer.fit_transform(tokenized_corpus)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5lQ10twVyUf"
   },
   "source": [
    "We have now have a matrix representation of our corpus, where rows are documents, and columns (or features) are words from the corpus. The value at any given point is the number of times that the word appears in that document. Once we have a document-term matrix, we could do a few different things with it, just within textacy, though we could take it and pass it into different algorithms within scikit-learn or other libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37KLE01TVyUg"
   },
   "outputs": [],
   "source": [
    "# Let's first look at some of the terms\n",
    "vectorizer.terms_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_I6y0JIVyUh"
   },
   "source": [
    "We can see that we are still getting a number of terms which ought to be filtered out, such as numbers and punctuation. We would want to clean this up more before vectorizing in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7c7uSmdnLOz"
   },
   "source": [
    "## Topic Modeling\n",
    "\n",
    "Let's look quickly at one examples of what we can do with a vectorized corpus. Topic modeling is very popular for semantic exploration of texts, and there are numerous implementations. Textacy uses implementations from scikit-learn. \n",
    "\n",
    "Our corpus is rather small for topic modeling, but just to see how it's done here, we'll go ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF2jrntfmz8I"
   },
   "outputs": [],
   "source": [
    "import textacy.tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFusfd9sm1dv"
   },
   "outputs": [],
   "source": [
    "model = textacy.tm.TopicModel(\"lda\", n_topics=10)\n",
    "model.fit(dtm)\n",
    "doc_topic_matrix = model.transform(dtm)\n",
    "doc_topic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zP_oC22nJLq"
   },
   "outputs": [],
   "source": [
    "for topic_idx, top_terms in model.top_topic_terms(vectorizer.id_to_term, top_n=10):\n",
    "  print(\"topic\", topic_idx, \":\", \"   \".join(top_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation survey\n",
    "Please, spend 1 minute answering these questions that can help us a lot on future workshops. \n",
    "\n",
    "https://go.ncsu.edu/dvs-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmNCMQIJnoKs"
   },
   "source": [
    "## Credits\n",
    "\n",
    "Originally written by Scott Bailey and co-taught with Simon Wiles at Stanford Libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Text Analysis with Python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "206px",
    "width": "555px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
