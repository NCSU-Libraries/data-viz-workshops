---
title: "Hands-on coding instruction"
author: "Ruth Okoilu"
date: "July 28, 2017"
output: github_document
---

## This instruction set features two (2) Machine Learning applications.

### The first example uses Regression analysis while the other uses Random Forest algorithm.

This is an example of how to perform Linear regression modelling.

We intend to fit a simple regression model. This model is a line.
Regression modelling is used to find equations that fit data

The equation is of the form:

y =  a + bx + ei

y is what we want to predict and x includes all the predictors required to form the model above.
a and b are coefficients determined by the **"lm"** function we'll use shortly.
Regression model is easy to implement but it often produces low performance models.
This method is useful when the variable involved can be modelled in a linear way.

For example, increase in age leads to increase in weight, or increase in age leads to decrease in the number of hairs on head.
This cannot be used in showing increase in library visitor per day of the week. This is usually Non linear.


## Example #1: Does Money Buy Happiness? Correlation Between Salary and Employee Satisfaction

```{r echo=TRUE}
# Install package "caret" if you do not have it already
#install.packages("caret")
#Load caret package
library(caret)

#Create a tidy dataset:
#  What makes this dataset tidy?

# earnings  - Employee Earnings
# s_rating  - Employee Satisfaction rating
# emp_data  - data.frame(earning, s_rating)
earnings <- c(120, 100, 700, 200, 60, 20, 200, 130, 150, 160, 170, 180, 190, 210, 220, 400, 550, 670, 695, 300)

s_rating<- c(50, 60, 80, 75, 50, 70, 75, 60, 50, 65, 70, 71,80, 82, 85, 80, 88, 90, 90, 60)

emp_data  <- data.frame(earnings, s_rating)

emp_data 


set.seed(222)
inTrain <- createDataPartition(y= emp_data$s_rating, p=0.6, list=FALSE)

training <- emp_data[inTrain,]
test <- emp_data[-inTrain,]
head(training)
summary(training)
```

We execute the line set.seed(222) above so that when analysis is reproduced, a similar result is gotten.

### Exploratory Data Analysis

You can also embed plots, for example:

```{r echo=TRUE}
par(cex=.8)
plot(earnings, s_rating, col = s_rating, main="Regression Modelling")

```

### Creating Our Model

We create and fit the line (formula) created by our model using the abline() function in R

```{r, echo=TRUE}
reg_model <- lm(s_rating ~ earnings, data=training)
summary(reg_model)

par(cex=.8)
plot(training$earnings, training$s_rating, col = s_rating, main="Regression Modelling")

# function to draw a regression line based on the model the machine created called reg_model
abline(reg_model)

# What are the coefficients a and b? To print ot the coefficients

print(coef(reg_model)[1])
print(coef(reg_model)[2])
```


From y = a + bx + ei (ei = error measures factors that we didn't take into consideration about the model)

Our model simply produced the formula:
Satisfaction = 0.04056(Earning) + 59.46977 



### Test Model

We could create a function to test our model

```{r  echo=TRUE}
predict_happiness <- function(x){
  Coef_1 = 0.04056
  Coef_2 = 59.46977
  Result<- (Coef_1 * x) + Coef_2 
  percent<- "%"
  cat(sprintf("The employee should be %s%s satisfied", Result, percent))
}
predict_happiness(test$earnings)

```
Another way to test is to use the predict function provided by the caret package

```{r, echo=TRUE}
# pred_rating - Predicted satisfaction rating
pred_rating <- predict(reg_model, test)
print(data.frame(test$s_rating, pred_rating))

```

Test data helps us to see how accurate our model is.
We can see that our model (the regression line) is not too precise.
It however, made an attempt to accurately predict the satisfaction rating of the empolyee in row 10 above.

### Check the accuracy of model visually


You can also embed plots, for example:

```{r , echo=TRUE}
par(mfrow=c(1,2))

plot(training$earnings, training$s_rating, col = s_rating, main="Regression Modelling")

abline(reg_model)  

plot(test$earnings, test$s_rating, col = s_rating, main="Regression Modelling")

abline(reg_model)  

```


###  Accuracy of Our Model using RMSE

RMSE (root-mean-square deviation) - calculate mean squared errors on test sets
RMSE measures deviation of predicted points to original value

You can also embed plots, for example:

```{r , echo=TRUE}

# Realistic check because test dataset is new dataset
sqrt(sum((predict(reg_model, test) - test$s_rating)^2))

```

The above shows that our model's RMSE is 25.80565. A smaller value means more accurate model.


## Example #2: Predicting a person's wage based on age, profession and level of education


```{r echo=TRUE}
# Install the necessary packages
#install.packages("ISLR")
#install.packages(randomForest)
library(ISLR)
library(ggplot2)
library(caret)
library(randomForest)
```

Know more about the Wage dataset
```{r echo=TRUE}
# Load "wage" dataset - a dataset stored in R
data(Wage)
summary(Wage)
```


### Some Feature Engineering

We don't need the variable "logwage" for our analysis, so we remove it.

```{r echo=TRUE}
Wage<- subset(Wage, select=- c(logwage))

```


### Exploratory data analysis

```{r echo=TRUE}
qplot(age, wage, data=Wage, colour = race)
qplot(age, wage, data=Wage, colour=education)

```
### Creating Our Model - Partition the data into Training and Test sets


```{r, echo=TRUE}
inTrain<- createDataPartition(y = Wage$wage, p=0.7, list= FALSE)
training<- Wage[inTrain,]
testing<- Wage[-inTrain,]
dim(training); dim(testing)

qplot(age, wage, data=training)
qplot(age, wage, data=training, colour=education)

set.seed(150)

rf_model <- randomForest(wage ~ age + jobclass + education, data = training, importance = TRUE, ntree=200)

#PRINT OUT to check RMSE

print(rf_model)

```


### Test Model

Running test data on your model and comparing it to the real outcome. We'll use the predict function provided by the caret package

```{r  echo=TRUE}

pred<- predict(rf_model, testing)
qplot(wage, pred, colour=year, data=testing)

```

### Compare predicted wage to original wage of test dataset

```{r, echo=TRUE}
postResample(testing$wage, pred)
compare_result <- data.frame(testing$wage, pred)
head(compare_result) 

```



### Attempting to improve the model

The accuracy of our model is 

```{r , echo=TRUE}

# To check accuracy
print(rf_model)

# Check what variables affect our model the most and what variables to leave out in future analysis
importance(rf_model)
varImpPlot(rf_model)

```

<span style="color:blue">Mean Decrease Accuracy</span> (%IncMSE) - This shows how much our model accuracy decreases if we leave out that variable.

<span style="color:blue">Mean Decrease Gini</span> (IncNodePurity) - This is a measure of variable importance based on the Gini impurity index used for the calculating the splits in trees. 

The higher the value of mean decrease accuracy or mean decrease gini score, the higher the importance of the variable to our model. 

We can see that the predictor "education" plays an important role in the accuracy of our model. We might include other variables from the wage dataset into our analyses and compare our model's RMSE when this variables are present versus when absent.

Another attempt to improve the mode is to adjust the value of **ntree** and set it to the number that produces a better model while creating the rf_model.

