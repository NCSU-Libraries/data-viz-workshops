{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python_Open_Labs_Week1_filled.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1RRaslfrRbia"},"source":["**Setup**\r\n","\r\n","With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook."]},{"cell_type":"markdown","metadata":{"id":"FpbBQzdwReOX"},"source":["# Python Open Labs: Reading, exploring, and writing data with Pandas\r\n","\r\n","## Welcome!\r\n","\r\n","### Instructors\r\n","- Walt Gurley\r\n","- Claire Cahoon\r\n","- Scott Bailey\r\n","- Natalia Lopez\r\n","- Ashley Evans Bandy\r\n","\r\n","### Open Labs agenda\r\n","\r\n","1.   **Guided activity**: One of the instructors will share their screen to work through the guided activity and teach concepts along the way.\r\n","\r\n","2.   **Open lab time**: After the guided portion of the Open Lab, the rest of the time is for you to ask questions, work collaboratively, or have self-guided practice time. You will have access to instructors and peers for questions and support.\r\n","\r\n","Breakout rooms will be available if you would like to work in small groups. If you have trouble joining a room, ask in the chat to be moved into a room.\r\n","\r\n","### Learning objectives\r\n","\r\n","By the end of our workshop today, we hope you'll understand what the pandas library is and be able to work with pandas data structures like a `Series` and a `DataFrame`.\r\n","\r\n","### Today's Topics\r\n","- What is pandas, and how does it relate to Python?\r\n","- Importing and using pandas\r\n","- How to read data into pandas\r\n","- Common pandas data structures (`Series` and `DataFrame`)\r\n","- Referencing data in a `DataFrame`\r\n","- How to write data from pandas\r\n"]},{"cell_type":"markdown","metadata":{"id":"wnfvztEcR9B-"},"source":["### Using Zoom\r\n","\r\n","Please make sure that your mic is muted during the workshop.\r\n","\r\n","We will have live captioning enabled, you can switch this on and off from your toolbar at the bottom of the screen."]},{"cell_type":"markdown","metadata":{"id":"197ZHrVnR8z6"},"source":["### Asking questions\r\n","\r\n","Please feel free to ask questions in the Zoom chat throughout the demonstration.\r\n","\r\n","Other instructors will be monitoring chat on Zoom. They will answer as able, and will collect questions with answers that might help everyone to answer at the end of the demonstration.\r\n","\r\n","The open lab time is when you will be able to ask more questions and work together on the exercises."]},{"cell_type":"markdown","metadata":{"id":"YohJ7IZeTX31"},"source":["### Using Jupyter Notebooks and Google Colaboratory\r\n","\r\n","Jupyter notebooks are a way to write and run Python code in an interactive way. They're quickly becoming a standard way of putting together data, code, and written explanations or visualizations into a single document and sharing that. There are a lot of ways that you can run Jupyter notebooks, including just locally on your computer, but we've decided to use Google's Colaboratory notebook platform for this workshop.  Colaboratory is “a Google research project created to help disseminate machine learning education and research.”  If you would like to know more about Colaboratory in general, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\r\n","\r\n","Using the Google Colaboratory platform allows us to focus on learning and writing Python in the workshop rather than on setting up Python, which can sometimes take a bit of extra work depending on platforms, operating systems, and other installed applications. If you'd like to install a Python distribution locally, though, we're happy to help. Feel free to [get help from our graduate consultants](https://www.lib.ncsu.edu/dxl) or [schedule an appointment with Libraries staff](https://go.ncsu.edu/dvs-request)."]},{"cell_type":"markdown","metadata":{"id":"diWLAlRBTsWT"},"source":["## Guided Instruction\r\n","This week we're introducing the Pandas library for Python and working on importing, viewing, and referencing the data.\r\n","\r\n","Content Warning: This dataset contains information relating to violence towards animals. We understand that this may be distressing, and if you need to step away from the workshop we understand.\r\n","\r\n","In this section, we will work through examples using data from the [Federal Aviation Administration (FAA) Wildlife Strikes Database](https://wildlife.faa.gov/search). We have filtered the data to only include North Carolina.\r\n","\r\n","> \"The FAA Wildlife Strike Database contains records of reported wildlife strikes since 1990. Strike reporting is voluntary. Therefore, this database only represents the information we have received from airlines, airports, pilots, and other sources.\" - [FAA website](https://wildlife.faa.gov/home)"]},{"cell_type":"markdown","metadata":{"id":"K1QD9jJmyLZ0"},"source":["### What is a Python library?\n","\n","A \"Library\" in this context is a package of code that adds to the functionality of Python. Base Python offers a lot of features, but not everything -- Python libraries can be imported at the beginning of your code to use for your specific purpose. \n","\n","For example, you may import Matplotlib to create graphs and plots, or Natural Language Toolkit (NLTK) to do natural language processing. Today we will be using the pandas library to manipulate a dataset."]},{"cell_type":"markdown","metadata":{"id":"QBRN6sBjFn5m"},"source":["### What is Pandas?\r\n","\r\n","Pandas is a high-level data manipulation tool first created in 2008 by Wes McKinney. The name comes from the term “panel data,” an econometrics term for data sets that include observations over multiple time periods for the same individuals.<sup>[[wikipedia](https://en.wikipedia.org/wiki/Pandas_(software))]</sup>\r\n","\r\n","From Jake Vanderplas’ book [**Python Data Science Handbook**](http://shop.oreilly.com/product/0636920034919.do):\r\n","\r\n","> As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\r\n","\r\n","#### What does Pandas do?\r\n","* Reading and writing data from persistent storage\r\n","* Cleaning, filtering, and otherwise preparing data\r\n","* Calculating statistics and analyzing data\r\n","* Visualization with help from Matplotlib\r\n","\r\n","We can learn more about Pandas by using the help window in Google Colab."]},{"cell_type":"code","metadata":{"id":"jj_TJHcDcdnC"},"source":["# Type the function with a question mark afterwards and run the code to pull up a help window.\r\n","# Here we will find out more about Pandas\r\n","pd?"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s1V43ndUUeCd"},"source":["### Importing a Python library\r\n","\r\n","To use any library, we must import it into our Python document."]},{"cell_type":"code","metadata":{"id":"PDoDt0yF4Pxs"},"source":["# Import the Pandas library as pd (callable in our code as pd)\n","import pandas as pd\n","pd?"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Df1997BxURKU"},"source":["### Importing files into Pandas\r\n","We have prepared the data from the FAA website for this workshop. We will import those datasets into our notebook to use them for data analysis.\r\n","\r\n","Datasets can be stored in several types of files, including .csv, .json, .txt, .xls, .xlsx, and more. Here we will import a .csv file and a .json file.\r\n","\r\n","- [Preview the CSV file](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_1990-1999.csv)\r\n","- [Preview the JSON file](https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2010-2019.json)"]},{"cell_type":"markdown","metadata":{"id":"cTp3Z1jhe-8O"},"source":["CSV Files\r\n","\r\n","A comma separated values (CSV) file is a plain text file containing data separated by commas."]},{"cell_type":"code","metadata":{"id":"cPSnhS9w4TNy"},"source":["# Import a comma-sperated values (csv) file as a DataFrame\n","\n","# The file location\n","csv_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_1990-1999.csv'\n","\n","# Read in the file and print out the DataFrame\n","wl_strikes_csv = pd.read_csv(csv_file_url)\n","wl_strikes_csv.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NK-iUJ9buc9"},"source":["JSON Files\n","\n","JSON (JavaScript Object Notation) is a data storage format that uses name/value pairs to create objects and associative arrays. Learn more about [JSON files structure and syntax from W3Schools](https://www.w3schools.com/js/js_json_syntax.asp)"]},{"cell_type":"code","metadata":{"id":"sMH_cCgeVLhs"},"source":["# Importing a JavaScript object notation (JSON) file\n","\n","# The file location\n","json_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2010-2019.json'\n","\n","# Read in the file and print out the DataFrame\n","wl_strikes_json = pd.read_json(json_file_url)\n","wl_strikes_json.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xp61Ys2oVPZj"},"source":["### Pandas data structures\r\n","\r\n","Pandas uses two main data structures: `Series` and `DataFrame`.\r\n","\r\n","<img src=\"https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Data_Manipulation_with_Python/assets/nc_dataframes.png\" alt=\"DataFrames are composed of Series\" width=\"80%\">"]},{"cell_type":"markdown","metadata":{"id":"Y_CkSgllUPuY"},"source":["#### `Series`\r\n","A `Series` is a one-dimensional array of indexed data, or a single column of data. It can be thought of as a specialized dictionary or a generalized NumPy array. You can learn more about the Series data type in the [Pandas documentation for Series](https://pandas.pydata.org/pandas-docs/stable/reference/series.html)."]},{"cell_type":"markdown","metadata":{"id":"KYWGQkIuUSwI"},"source":["#### `DataFrame`\r\n","A `DataFrame` is a two-dimensional array composed of one or more `Series`, similar to tabluar data (think of Excel). They can optionally have an `Index` and have flexible row indices and flexible column names. \r\n","\r\n","It can be thought of as a generalization of a two-dimensional NumPy array, or a specialization of a dictionary in which each column name maps to a `Series` of column data. You can learn more about the DataFrame data type in the [Pandas documentation for DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).\r\n","\r\n","A `DataFrame` is made up of `Series` in a similar way in which a table is made up of columns. The only restriction is that each column must be of the same data type.  Many of the operations that can be performed on a `DataFrame` can also be performed on an individual `Series`."]},{"cell_type":"code","metadata":{"id":"EDTANvgUVRzr"},"source":["# The csv file we imported earlier was stored in a DataFrame.\n","# Let's look at that data:\n","wl_strikes_csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbokiHAn0RwT","executionInfo":{"status":"ok","timestamp":1614790828479,"user_tz":300,"elapsed":2773,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"92a39162-6945-43d4-dd39-edc2b2f5c942"},"source":["# You can also view the \"shape\" of the Dataframe\r\n","# This tells you how many rows and columns there are\r\n","wl_strikes_csv.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(669, 92)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfjKNKV5F5Ls","executionInfo":{"status":"ok","timestamp":1614790828479,"user_tz":300,"elapsed":2767,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"4b38fe9e-a252-4166-a847-110b5c738de7"},"source":["# A Series is a one-dimensional array, or one column of data\n","# When we take one column of a DataFrame, it is represented as a Series\n","airport = wl_strikes_csv['AIRPORT']\n","type(airport)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.series.Series"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"14A4pjHcGmcy"},"source":["# Now that we have created a Series, let's look at the data:\r\n","airport"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_jG372DGpLD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614790828481,"user_tz":300,"elapsed":2757,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"6ef53dd0-c00d-40bd-d2ea-6c8683b125c8"},"source":["# You can also see the shape of a Series\r\n","# Since a Series only has one column, it will tell you how many rows there are\r\n","airport.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(669,)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"i9_dDcgO1c_B"},"source":["# You can convert a Series to a list with to_list()\r\n","airport.to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LSSnc8FyVycL"},"source":["### Exploring your data\r\n","\r\n","Now that we have our data, we can use Pandas to explore our data for analysis. This can be useful if you are new to a dataset to see what's there and how you should start analyzing."]},{"cell_type":"markdown","metadata":{"id":"QYn7Bu8rHv6i"},"source":["#### View DataFrame column labels\n","\n","Our DataFrame has 92 columns. We can quickly view the label names for each column using the DataFrame `columns` property."]},{"cell_type":"code","metadata":{"id":"IGHafxVsHaLG"},"source":["# View column labels (headers)\n","wl_strikes_csv.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DrgiOCTevH3P"},"source":["#### View summaries of a DataFrame\n","\n","We can quickly generate summaries of our DataFrame to observe some basic statistics and information such as column data types and non-null value counts."]},{"cell_type":"code","metadata":{"id":"RB9nwV--sd5a"},"source":["# Get summary statistics of DataFrame columns using \"describe()\" (only includes\r\n","# numerical data types)\r\n","wl_strikes_csv.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOCCBvV043UT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614790828484,"user_tz":300,"elapsed":2735,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"ee3b8276-4391-4e82-9e89-95a364991a7c"},"source":["# Get summary statistics of single column using \"describe()\"\n","wl_strikes_csv['AIRCRAFT'].describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count             669\n","unique             96\n","top       FOKKER F100\n","freq               62\n","Name: AIRCRAFT, dtype: object"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"dI5VjlC71rY8"},"source":["# Summarize column data types, non-null values, and memory usage using \"info()\"\n","wl_strikes_csv.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJccXIWLH98S"},"source":["#### Referencing and indexing a DataFrame"]},{"cell_type":"markdown","metadata":{"id":"ql6K-MTxXjAh"},"source":["Referencing Rows"]},{"cell_type":"code","metadata":{"id":"98nMIhphH6kP"},"source":["# Reference a row by index label\r\n","# Returns a Series\r\n","\r\n","# Access first row of wl_strikes_csv by index label\r\n","# In this case the index label is 0\r\n","wl_strikes_csv.loc[0]\r\n","\r\n","# Access first row of wl_strikes_json by index label\r\n","# In this case the index label is not 0\r\n","# wl_strikes_json.loc[0]\r\n","wl_strikes_json.loc[1080125]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vld2Jz8ZKgdH","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1614790829247,"user_tz":300,"elapsed":3465,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"30e19d6c-8c15-47a0-c0f1-994dc4e9f093"},"source":["# Reference multiple rows by index label (in this case the index label 0 through 2)\r\n","# Returns a DataFrame\r\n","wl_strikes_csv.loc[0:2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>INDX_NR</th>\n","      <th>INCIDENT_DATE</th>\n","      <th>INCIDENT_MONTH</th>\n","      <th>INCIDENT_YEAR</th>\n","      <th>TIME</th>\n","      <th>TIME_OF_DAY</th>\n","      <th>AIRPORT_ID</th>\n","      <th>AIRPORT</th>\n","      <th>RUNWAY</th>\n","      <th>STATE</th>\n","      <th>FAAREGION</th>\n","      <th>LOCATION</th>\n","      <th>ENROUTE STATE</th>\n","      <th>OPID</th>\n","      <th>OPERATOR</th>\n","      <th>REG</th>\n","      <th>FLT</th>\n","      <th>AIRCRAFT</th>\n","      <th>AMA</th>\n","      <th>AMO</th>\n","      <th>EMA</th>\n","      <th>EMO</th>\n","      <th>AC_CLASS</th>\n","      <th>AC_MASS</th>\n","      <th>TYPE_ENG</th>\n","      <th>NUM_ENGS</th>\n","      <th>ENG_1_POS</th>\n","      <th>ENG_2_POS</th>\n","      <th>ENG_3_POS</th>\n","      <th>ENG_4_POS</th>\n","      <th>PHASE_OF_FLIGHT</th>\n","      <th>HEIGHT</th>\n","      <th>SPEED</th>\n","      <th>DISTANCE</th>\n","      <th>SKY</th>\n","      <th>PRECIPITATION</th>\n","      <th>AOS</th>\n","      <th>COST_REPAIRS</th>\n","      <th>OTHER_COST</th>\n","      <th>COST_REPAIRS_INFL_ADJ</th>\n","      <th>...</th>\n","      <th>STR_ENG2</th>\n","      <th>DAM_ENG2</th>\n","      <th>STR_ENG3</th>\n","      <th>DAM_ENG3</th>\n","      <th>STR_ENG4</th>\n","      <th>DAM_ENG4</th>\n","      <th>STR_PROP</th>\n","      <th>DAM_PROP</th>\n","      <th>STR_WING_ROT</th>\n","      <th>DAM_WING_ROT</th>\n","      <th>STR_FUSE</th>\n","      <th>DAM_FUSE</th>\n","      <th>STR_LG</th>\n","      <th>DAM_LG</th>\n","      <th>STR_TAIL</th>\n","      <th>DAM_TAIL</th>\n","      <th>STR_LGHTS</th>\n","      <th>DAM_LGHTS</th>\n","      <th>STR_OTHER</th>\n","      <th>DAM_OTHER</th>\n","      <th>OTHER_SPECIFY</th>\n","      <th>EFFECT</th>\n","      <th>EFFECT_OTHER</th>\n","      <th>SPECIES_ID</th>\n","      <th>REMARKS</th>\n","      <th>REMAINS_COLLECTED</th>\n","      <th>REMAINS_SENT</th>\n","      <th>WARNED</th>\n","      <th>BIRDS_SEEN</th>\n","      <th>BIRDS_STRUCK</th>\n","      <th>SIZE</th>\n","      <th>NR_INJURIES</th>\n","      <th>NR_FATALITIES</th>\n","      <th>COMMENT</th>\n","      <th>REPORTER_NAME</th>\n","      <th>REPORTER_TITLE</th>\n","      <th>SOURCE</th>\n","      <th>PERSON</th>\n","      <th>LUPDATE</th>\n","      <th>TRANSFER</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>633309</td>\n","      <td>1999-12-24</td>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td>10:15</td>\n","      <td>Day</td>\n","      <td>KCLT</td>\n","      <td>CHARLOTTE/DOUGLAS INTL ARPT</td>\n","      <td>18R</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USA</td>\n","      <td>1US AIRWAYS</td>\n","      <td>N523AU</td>\n","      <td></td>\n","      <td>B-737-300</td>\n","      <td>148</td>\n","      <td>24.0</td>\n","      <td>10.0</td>\n","      <td>1.0</td>\n","      <td>A</td>\n","      <td>4.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Landing Roll</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>No Cloud</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>O2111</td>\n","      <td>4 BIRDS.FLT 1539. STRIKE REPTS DIFFER AS TO PH...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>Unknown</td>\n","      <td>2-10</td>\n","      <td>2-10</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SOURCE = TWO XXXX-X REPTS /Legacy Record=XXXXXX/</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7</td>\n","      <td>Air Transport Operations</td>\n","      <td>2000-03-10</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>634726</td>\n","      <td>1999-12-15</td>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td></td>\n","      <td>Day</td>\n","      <td>KRDU</td>\n","      <td>RALEIGH-DURHAM INTL</td>\n","      <td>23R</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>CDR</td>\n","      <td>CANADIAN REGIONAL AIRLINES</td>\n","      <td>C-FPCR</td>\n","      <td></td>\n","      <td>FOKKER F28 MK 1000</td>\n","      <td>372</td>\n","      <td>4.0</td>\n","      <td>37.0</td>\n","      <td>43.0</td>\n","      <td>A</td>\n","      <td>4.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Approach</td>\n","      <td>20.0</td>\n","      <td>130.0</td>\n","      <td>NaN</td>\n","      <td>No Cloud</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>UNKBS</td>\n","      <td>NO EVIDENCE OF BEING STRUCK OR DAMAGE REPTD BY...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>Yes</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>/Legacy Record=XXXXXX/</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7</td>\n","      <td>NaN</td>\n","      <td>2000-03-09</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>636216</td>\n","      <td>1999-12-14</td>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td>07:40</td>\n","      <td>Day</td>\n","      <td>KCLT</td>\n","      <td>CHARLOTTE/DOUGLAS INTL ARPT</td>\n","      <td>18R</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>USA</td>\n","      <td>1US AIRWAYS</td>\n","      <td>N955VJ</td>\n","      <td></td>\n","      <td>DC-9-30</td>\n","      <td>583</td>\n","      <td>21.0</td>\n","      <td>34.0</td>\n","      <td>10.0</td>\n","      <td>A</td>\n","      <td>4.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Approach</td>\n","      <td>100.0</td>\n","      <td>132.0</td>\n","      <td>NaN</td>\n","      <td>Some Cloud</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>YL001</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>No</td>\n","      <td>2-10</td>\n","      <td>2-10</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SOURCE = TWO XXXX-X REPTS /Legacy Record=XXXXXX/</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7</td>\n","      <td>Tower</td>\n","      <td>2000-03-09</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 92 columns</p>\n","</div>"],"text/plain":["   INDX_NR INCIDENT_DATE   ...     LUPDATE  TRANSFER\n","0   633309     1999-12-24  ...  2000-03-10     False\n","1   634726     1999-12-15  ...  2000-03-09     False\n","2   636216     1999-12-14  ...  2000-03-09     False\n","\n","[3 rows x 92 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"FtY5Fh_ZH6EB"},"source":["# Reference a row or multiple rows by zero-based integer position\r\n","\r\n","# Access first row of wl_strikes_csv by row integer value\r\n","# In this case the row is row 0\r\n","wl_strikes_csv.iloc[0]\r\n","\r\n","# Access first row of wl_strikes_json by row integer value\r\n","# In this case the row is also row 0\r\n","wl_strikes_json.iloc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"54qnMnQ_K82s"},"source":["# Reference multiple rows by row number (in this case rows 0 through 2)\r\n","# Note that this time the range doesn't include the stop number\r\n","wl_strikes_csv.iloc[0:3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DCdFsQCSXmrB"},"source":["Referencing Columns"]},{"cell_type":"code","metadata":{"id":"nP0sJUqTH-bj"},"source":["# Referencing a column by column label (in this case, \"INDX_NR\")\r\n","wl_strikes_csv['INDX_NR']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_QFuy9xH-SY"},"source":["# Referencing multiple columns by a list of column labels \r\n","# (in this case, the columns \"INDX_NR\" and \"AIRPORT\")\r\n","wl_strikes_csv[['INDX_NR', 'AIRPORT']]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ofsu9wMSX37b"},"source":["Referencing both rows and columns"]},{"cell_type":"code","metadata":{"id":"Mo6ItH-WIEvh"},"source":["# Referencing a subset of rows and columns using index and column labels\n","# Note that we're using a range of column labels instead of a list\n","# Make sure that your column range starts with the leftmost label\n","wl_strikes_csv.loc[:10, 'INDX_NR':'TIME']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vqjDtbr4OvIL"},"source":["### Writing data to a file"]},{"cell_type":"code","metadata":{"id":"Pu5h4CcfOxzr"},"source":["# Save the subset from the previous cell in a variable\r\n","first_ten = wl_strikes_csv.loc[:10, 'INDX_NR':'TIME']\r\n","\r\n","# Write to csv\r\n","first_ten.to_csv(\"new_data.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1Te-Bz5lKpZ"},"source":["#Write to an Excel file\r\n","first_ten.to_excel(\"new_data.xls\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzIcnroVlK7B"},"source":["# Write to a JSON file\r\n","first_ten.to_json(\"new_data.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x7fVAHmIWYcC"},"source":["----\r\n","## Open work time\r\n","You can use this time to ask questions, collaborate, or work on the following activities (on your own or in a group). "]},{"cell_type":"markdown","metadata":{"id":"ipiIOjUiGIA3"},"source":["### Exercise 1: Read in an Excel file\r\n","Take this Excel file, read it into a DataFrame, and print out the first five rows of the DataFrame.\r\n","\r\n","\r\n","\r\n","> Hint: the syntax is very similar to reading a .csv file.\r\n","\r\n","\r\n","\r\n","Link to the file: https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2000-2009.xlsx?raw=true"]},{"cell_type":"code","metadata":{"id":"Ji--t8MFcdLL","colab":{"base_uri":"https://localhost:8080/","height":533},"executionInfo":{"status":"ok","timestamp":1614791484014,"user_tz":300,"elapsed":2343,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"ed1c6359-6b6a-40b9-8d11-f35196600b46"},"source":["# Save the url as a variable\r\n","xls_file_url = 'https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2000-2009.xlsx?raw=true'\r\n","\r\n","# Read the file in\r\n","wl_strikes_xls = pd.read_excel(xls_file_url)\r\n","\r\n","# View the file\r\n","wl_strikes_xls.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>INDX_NR</th>\n","      <th>INCIDENT_DATE</th>\n","      <th>INCIDENT_MONTH</th>\n","      <th>INCIDENT_YEAR</th>\n","      <th>TIME</th>\n","      <th>TIME_OF_DAY</th>\n","      <th>AIRPORT_ID</th>\n","      <th>AIRPORT</th>\n","      <th>RUNWAY</th>\n","      <th>STATE</th>\n","      <th>FAAREGION</th>\n","      <th>LOCATION</th>\n","      <th>ENROUTE STATE</th>\n","      <th>OPID</th>\n","      <th>OPERATOR</th>\n","      <th>REG</th>\n","      <th>FLT</th>\n","      <th>AIRCRAFT</th>\n","      <th>AMA</th>\n","      <th>AMO</th>\n","      <th>EMA</th>\n","      <th>EMO</th>\n","      <th>AC_CLASS</th>\n","      <th>AC_MASS</th>\n","      <th>TYPE_ENG</th>\n","      <th>NUM_ENGS</th>\n","      <th>ENG_1_POS</th>\n","      <th>ENG_2_POS</th>\n","      <th>ENG_3_POS</th>\n","      <th>ENG_4_POS</th>\n","      <th>PHASE_OF_FLIGHT</th>\n","      <th>HEIGHT</th>\n","      <th>SPEED</th>\n","      <th>DISTANCE</th>\n","      <th>SKY</th>\n","      <th>PRECIPITATION</th>\n","      <th>AOS</th>\n","      <th>COST_REPAIRS</th>\n","      <th>OTHER_COST</th>\n","      <th>COST_REPAIRS_INFL_ADJ</th>\n","      <th>...</th>\n","      <th>STR_ENG2</th>\n","      <th>DAM_ENG2</th>\n","      <th>STR_ENG3</th>\n","      <th>DAM_ENG3</th>\n","      <th>STR_ENG4</th>\n","      <th>DAM_ENG4</th>\n","      <th>STR_PROP</th>\n","      <th>DAM_PROP</th>\n","      <th>STR_WING_ROT</th>\n","      <th>DAM_WING_ROT</th>\n","      <th>STR_FUSE</th>\n","      <th>DAM_FUSE</th>\n","      <th>STR_LG</th>\n","      <th>DAM_LG</th>\n","      <th>STR_TAIL</th>\n","      <th>DAM_TAIL</th>\n","      <th>STR_LGHTS</th>\n","      <th>DAM_LGHTS</th>\n","      <th>STR_OTHER</th>\n","      <th>DAM_OTHER</th>\n","      <th>OTHER_SPECIFY</th>\n","      <th>EFFECT</th>\n","      <th>EFFECT_OTHER</th>\n","      <th>SPECIES_ID</th>\n","      <th>REMARKS</th>\n","      <th>REMAINS_COLLECTED</th>\n","      <th>REMAINS_SENT</th>\n","      <th>WARNED</th>\n","      <th>BIRDS_SEEN</th>\n","      <th>BIRDS_STRUCK</th>\n","      <th>SIZE</th>\n","      <th>NR_INJURIES</th>\n","      <th>NR_FATALITIES</th>\n","      <th>COMMENT</th>\n","      <th>REPORTER_NAME</th>\n","      <th>REPORTER_TITLE</th>\n","      <th>SOURCE</th>\n","      <th>PERSON</th>\n","      <th>LUPDATE</th>\n","      <th>TRANSFER</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>707074</td>\n","      <td>2009-12-24</td>\n","      <td>12</td>\n","      <td>2009</td>\n","      <td>07:52</td>\n","      <td>Dawn</td>\n","      <td>KCLT</td>\n","      <td>CHARLOTTE/DOUGLAS INTL ARPT</td>\n","      <td>36C</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>JIA</td>\n","      <td>PSA AIRLINES</td>\n","      <td>N218PS</td>\n","      <td></td>\n","      <td>CRJ100/200</td>\n","      <td>188</td>\n","      <td>10.0</td>\n","      <td>22.0</td>\n","      <td>4.0</td>\n","      <td>A</td>\n","      <td>3.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Approach</td>\n","      <td>100.0</td>\n","      <td>138.0</td>\n","      <td>NaN</td>\n","      <td>No Cloud</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>UNKBS</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>Unknown</td>\n","      <td>2-10</td>\n","      <td>1</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>/Legacy Record=XXXXXX/</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7</td>\n","      <td>Airport Operations</td>\n","      <td>2010-04-29</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>707361</td>\n","      <td>2009-12-13</td>\n","      <td>12</td>\n","      <td>2009</td>\n","      <td></td>\n","      <td>Day</td>\n","      <td>KILM</td>\n","      <td>WILMINGTON INTL</td>\n","      <td>17</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ASH</td>\n","      <td>MESA AIRLINES</td>\n","      <td></td>\n","      <td></td>\n","      <td>EMB-145</td>\n","      <td>332</td>\n","      <td>14.0</td>\n","      <td>1.0</td>\n","      <td>10.0</td>\n","      <td>A</td>\n","      <td>3.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Climb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Overcast</td>\n","      <td>Rain</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>PART NOT REPTD</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>UNKBM</td>\n","      <td>UNKNOWN TYPE OF BIRD STRUCK. PILOT REPTD HITTI...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>No</td>\n","      <td></td>\n","      <td>1</td>\n","      <td>Medium</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>XXXX-XX-XX-XXXXXX /Legacy Record=XXXXXX/</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7-E</td>\n","      <td>Airport Operations</td>\n","      <td>2010-04-29</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>707050</td>\n","      <td>2009-12-11</td>\n","      <td>12</td>\n","      <td>2009</td>\n","      <td>07:26</td>\n","      <td>Day</td>\n","      <td>KILM</td>\n","      <td>WILMINGTON INTL</td>\n","      <td>35</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1ASQ</td>\n","      <td>ATLANTIC SOUTHEAST</td>\n","      <td>N683AS?</td>\n","      <td>4939</td>\n","      <td>CRJ100/200</td>\n","      <td>188</td>\n","      <td>10.0</td>\n","      <td>22.0</td>\n","      <td>4.0</td>\n","      <td>A</td>\n","      <td>3.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Take-off Run</td>\n","      <td>0.0</td>\n","      <td>130.0</td>\n","      <td>0.0</td>\n","      <td>Some Cloud</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>YL001</td>\n","      <td>WE SAW 2 SML BIRDS AND 2 HIT WINDSHLD. PILOT R...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>No</td>\n","      <td>2-10</td>\n","      <td>2-10</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SOURCE = TWO XXXX-X (XXXX-XX-XX-XXXXXX &amp; XXXXX...</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7-E</td>\n","      <td>Air Transport Operations</td>\n","      <td>2010-04-08</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>707146</td>\n","      <td>2009-12-10</td>\n","      <td>12</td>\n","      <td>2009</td>\n","      <td>16:45</td>\n","      <td>Day</td>\n","      <td>KCLT</td>\n","      <td>CHARLOTTE/DOUGLAS INTL ARPT</td>\n","      <td>36C</td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>JIA</td>\n","      <td>PSA AIRLINES</td>\n","      <td>N718PS</td>\n","      <td>215</td>\n","      <td>CRJ700</td>\n","      <td>188</td>\n","      <td>16.0</td>\n","      <td>22.0</td>\n","      <td>4.0</td>\n","      <td>A</td>\n","      <td>4.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Take-off Run</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>Some Cloud</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>None, Precautionary Landing</td>\n","      <td>NaN</td>\n","      <td>YL001</td>\n","      <td>ID BY SMITHSONIAN. FAA 3952. DNA.</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>Yes</td>\n","      <td></td>\n","      <td>2-10</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SOURCE = THREE XXXX-X (XXXX-XX-XX-XXXXXX &amp; RX)...</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>FAA Form 5200-7-E</td>\n","      <td>Airport Operations</td>\n","      <td>2010-08-19</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>707624</td>\n","      <td>2009-12-08</td>\n","      <td>12</td>\n","      <td>2009</td>\n","      <td>07:30</td>\n","      <td>Dawn</td>\n","      <td>KCLT</td>\n","      <td>CHARLOTTE/DOUGLAS INTL ARPT</td>\n","      <td></td>\n","      <td>NC</td>\n","      <td>ASO</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ASH</td>\n","      <td>MESA AIRLINES</td>\n","      <td>N935LR</td>\n","      <td>2604</td>\n","      <td>CRJ900</td>\n","      <td>188</td>\n","      <td>17.0</td>\n","      <td>22.0</td>\n","      <td>4.0</td>\n","      <td>A</td>\n","      <td>4.0</td>\n","      <td>D</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Approach</td>\n","      <td>500.0</td>\n","      <td>133.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>UNKBS</td>\n","      <td>NO DMG TO A/C.</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>Yes</td>\n","      <td>2-10</td>\n","      <td>1</td>\n","      <td>Small</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>/Legacy Record=XXXXXX/</td>\n","      <td>REDACTED</td>\n","      <td>REDACTED</td>\n","      <td>Air Transport Report</td>\n","      <td>Air Transport Operations</td>\n","      <td>2010-04-29</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 92 columns</p>\n","</div>"],"text/plain":["   INDX_NR INCIDENT_DATE   ...     LUPDATE  TRANSFER\n","0   707074     2009-12-24  ...  2010-04-29     False\n","1   707361     2009-12-13  ...  2010-04-29     False\n","2   707050     2009-12-11  ...  2010-04-08     False\n","3   707146     2009-12-10  ...  2010-08-19     False\n","4   707624     2009-12-08  ...  2010-04-29     False\n","\n","[5 rows x 92 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"qEWRXGuubDfE"},"source":["### Exercise 2: Indexing cells\r\n","\r\n","Use referencing and indexing to answer the following questions by finding the data in the rows, columns, and/or cells. \r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"WfxKanr3aY6F"},"source":["#### 2a. Time of day\r\n","Airlines are interested in when they should schedule flights to minimize collisions. What is the time of day for each incident? Create a `Series` of the time of day (`TIME_OF_DAY`)"]},{"cell_type":"code","metadata":{"id":"9HrY_oNqckxz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614791708046,"user_tz":300,"elapsed":703,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"81dcb32f-4b4a-40f4-98bb-4c816fe9d37c"},"source":["# 2a. Create a `Series` of the time of day (`TIME_OF_DAY`)\r\n","time_of_day = wl_strikes_csv['TIME_OF_DAY']\r\n","\r\n","# Print new Series\r\n","time_of_day"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        Day\n","1        Day\n","2        Day\n","3       Dusk\n","4        NaN\n","       ...  \n","664      Day\n","665      Day\n","666      Day\n","667    Night\n","668     Dusk\n","Name: TIME_OF_DAY, Length: 669, dtype: object"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"nlEFmkWgabWq"},"source":["#### 2b. Date and time\r\n","We want to find out when most of these collisions occur. What is the exact date and time of each incident? Print the third, fourth, and fifth columns from the data (`INCIDENT_MONTH`,\t`INCIDENT_YEAR`, and\t`TIME`)."]},{"cell_type":"code","metadata":{"id":"KBaZgZcSckqD","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1614790831016,"user_tz":300,"elapsed":5170,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"49debeb2-0138-4d05-dc02-45423db275e9"},"source":["# 2b. Print the third, fourth, and fifth columns from the data \r\n","# (`INCIDENT_MONTH`, `INCIDENT_YEAR`, and `TIME`).\r\n","wl_strikes_csv[['INCIDENT_MONTH', 'INCIDENT_YEAR', 'TIME']]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>INCIDENT_MONTH</th>\n","      <th>INCIDENT_YEAR</th>\n","      <th>TIME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td>10:15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td>07:40</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td>17:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12</td>\n","      <td>1999</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>664</th>\n","      <td>6</td>\n","      <td>1990</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>665</th>\n","      <td>5</td>\n","      <td>1990</td>\n","      <td>11:35</td>\n","    </tr>\n","    <tr>\n","      <th>666</th>\n","      <td>4</td>\n","      <td>1990</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>667</th>\n","      <td>3</td>\n","      <td>1990</td>\n","      <td>21:30</td>\n","    </tr>\n","    <tr>\n","      <th>668</th>\n","      <td>1</td>\n","      <td>1985</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>669 rows × 3 columns</p>\n","</div>"],"text/plain":["     INCIDENT_MONTH  INCIDENT_YEAR   TIME\n","0                12           1999  10:15\n","1                12           1999       \n","2                12           1999  07:40\n","3                12           1999  17:00\n","4                12           1999       \n","..              ...            ...    ...\n","664               6           1990       \n","665               5           1990  11:35\n","666               4           1990       \n","667               3           1990  21:30\n","668               1           1985       \n","\n","[669 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"Vn0xaQufdoWm"},"source":["#### 2c. Access the 126th row\n","\n","Use row indexing to find the data in the 126th row in the `wl_strikes_json` DataFrame. Check that your result is correct by making sure your `INCIDENT_DATE` value is `2020-07-17`.\n","\n","> Tip: Remember that the integer-based row location is zero based\n","\n"]},{"cell_type":"code","metadata":{"id":"q3Bs5MEAeAtn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614790831018,"user_tz":300,"elapsed":5168,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"f093ed85-03a7-4899-ce1d-3d78931975d0"},"source":["# 2c. Access the 126th row from the 'wl_strikes_json` DataFrame\n","wl_strikes_json.iloc[125]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["INCIDENT_DATE            2020-07-17\n","INCIDENT_MONTH                    7\n","INCIDENT_YEAR                  2020\n","TIME                          06:00\n","TIME_OF_DAY                     Day\n","                        ...        \n","REPORTER_TITLE             REDACTED\n","SOURCE            FAA Form 5200-7-E\n","PERSON                        Pilot\n","LUPDATE                  2020-08-05\n","TRANSFER                      False\n","Name: 1008687, Length: 91, dtype: object"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"ua1uIGpgad7i"},"source":["#### 2d. Cloud cover\r\n","A particular airline has nine flights that they want to compare to see if the cloud cover in the area had anything to do with the collision. Print rows 60-65 and the columns `INDX_NR`, `SKY`, `PHASE_OF_FLIGHT`, and `AIRPORT`"]},{"cell_type":"code","metadata":{"id":"z0Ysc1yuckhC","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1614790831018,"user_tz":300,"elapsed":5160,"user":{"displayName":"Ashley Evans Bandy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEnggm2Xb6QnXpmQaXw4S5OovXByctlJmtN-OizA=s64","userId":"14475997041039881783"}},"outputId":"2822bdcb-5890-4eaf-affe-fc9bc2a5fea4"},"source":["# 2d. Print rows 60-65 and the columns 'INDX_NR', 'SKY', 'PHASE_OF_FLIGHT', and\r\n","# 'AIRPORT'\r\n","cloud_cover = wl_strikes_csv.loc[60:65, ['INDX_NR', 'SKY', 'PHASE_OF_FLIGHT', 'AIRPORT']]\r\n","cloud_cover"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>INDX_NR</th>\n","      <th>SKY</th>\n","      <th>PHASE_OF_FLIGHT</th>\n","      <th>AIRPORT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>60</th>\n","      <td>631616</td>\n","      <td>Some Cloud</td>\n","      <td>Climb</td>\n","      <td>RALEIGH-DURHAM INTL</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>627351</td>\n","      <td>NaN</td>\n","      <td>Take-off Run</td>\n","      <td>KINSTON REGIONAL JETPORT AT STALLINGS FIELD</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>635160</td>\n","      <td>Some Cloud</td>\n","      <td>Approach</td>\n","      <td>PIEDMONT TRIAD INTL</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>626190</td>\n","      <td>Overcast</td>\n","      <td>Climb</td>\n","      <td>RALEIGH-DURHAM INTL</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>635214</td>\n","      <td>No Cloud</td>\n","      <td>Take-off Run</td>\n","      <td>ALBERT J ELLIS</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>634350</td>\n","      <td>Overcast</td>\n","      <td>Take-off Run</td>\n","      <td>RALEIGH-DURHAM INTL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    INDX_NR  ...                                      AIRPORT\n","60   631616  ...                          RALEIGH-DURHAM INTL\n","61   627351  ...  KINSTON REGIONAL JETPORT AT STALLINGS FIELD\n","62   635160  ...                          PIEDMONT TRIAD INTL\n","63   626190  ...                          RALEIGH-DURHAM INTL\n","64   635214  ...                               ALBERT J ELLIS\n","65   634350  ...                          RALEIGH-DURHAM INTL\n","\n","[6 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"9aREW1K4anHc"},"source":["### Exercise 3: Write to a file\r\n","Take the your result in exercise 2d. (or another DataFrame you have created), and write it to a .csv file."]},{"cell_type":"code","metadata":{"id":"9lL37D4hcg2b"},"source":["# Write to a new .csv file\r\n","cloud_cover.to_csv(\"exercise3.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_dY4wqNdRSD"},"source":["## Further resources\r\n","\r\n","### Filled version of this notebook\r\n","\r\n","[Python Open Labs Week 1 filled notebook](https://colab.research.google.com/github/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/Reading_exploring_and_writing_data_with_Pandas/Python_Open_Labs_Week1_filled.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises.\r\n","\r\n","### Learning resources\r\n","\r\n","- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\r\n","- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\r\n","\r\n","### Finding help with pandas\r\n","\r\n","The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."]},{"cell_type":"markdown","metadata":{"id":"MAAF-mLyRqeE"},"source":["## Evaluation Survey\r\n","Please, spend 1 minute answering these questions that help improve future workshops.\r\n","\r\n","https://go.ncsu.edu/dvs-eval"]},{"cell_type":"markdown","metadata":{"id":"i6Sj-7OYR5JL"},"source":["## Credits\r\n","\r\n","This workshop was created by Claire Cahoon and Walt Gurley, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."]}]}