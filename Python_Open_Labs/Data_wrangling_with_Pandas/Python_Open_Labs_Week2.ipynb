{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python_Open_Labs_Week2.ipynb","provenance":[{"file_id":"12Rme5FLxDFpTFAldfgsleGG6eyXw2ewl","timestamp":1615288363335}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1RRaslfrRbia"},"source":["##  Setup\r\n","\r\n","With this Google Colaboratory (Colab) notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own Google user account, so you can edit it in any way you like -- you can even take notes directly in the notebook."]},{"cell_type":"markdown","metadata":{"id":"FpbBQzdwReOX"},"source":["# Python Open Labs: Data wrangling with Pandas\r\n","\r\n","## Welcome!\r\n","\r\n","### Instructors\r\n","- Scott Bailey\r\n","- Ashley Evans Bandy\r\n","- Claire Cahoon\r\n","- Walt Gurley\r\n","- Natalia Lopez\r\n","\r\n","### Open Labs agenda\r\n","\r\n","1.   **Guided activity**: One of the instructors will share their screen to work through the guided activity and teach concepts along the way.\r\n","\r\n","2.   **Open lab time**: After the guided portion of the Open Lab, the rest of the time is for you to ask questions, work collaboratively, or have self-guided practice time. You will have access to instructors and peers for questions and support.\r\n","\r\n","Breakout rooms will be available if you would like to work in small groups. If you have trouble joining a room, ask in the chat to be moved into a room.\r\n","\r\n","### Learning objectives\r\n","\r\n","By the end of our workshop today, we hope you'll understand what the Pandas library is and be able to use Pandas to manipulate data within DataFrames.\r\n","\r\n","### Today's Topics\r\n","- Editing DataFrame labels and headers\r\n","- Concatonating DataFrames\r\n","- Merging DataFrames\r\n","- Adding and removing columns\r\n"]},{"cell_type":"markdown","metadata":{"id":"wnfvztEcR9B-"},"source":["### Using Zoom\r\n","\r\n","Please make sure that your mic is muted during the workshop.\r\n","\r\n","We will have live captioning enabled, you can switch this on and off from your toolbar at the bottom of the screen."]},{"cell_type":"markdown","metadata":{"id":"197ZHrVnR8z6"},"source":["### Asking questions\r\n","\r\n","Please feel free to ask questions in the Zoom chat throughout the demonstration.\r\n","\r\n","Other instructors will be monitoring chat on Zoom. They will answer as able, and will collect questions with answers that might help everyone to answer at the end of the demonstration.\r\n","\r\n","The open lab time is when you will be able to ask more questions and work together on the exercises."]},{"cell_type":"markdown","metadata":{"id":"YohJ7IZeTX31"},"source":["### Using Jupyter Notebooks and Google Colaboratory\r\n","\r\n","Jupyter notebooks are a way to write and run Python code in an interactive way. They're quickly becoming a standard way of putting together data, code, and written explanations or visualizations into a single document and sharing that. There are a lot of ways that you can run Jupyter notebooks, including just locally on your computer, but we've decided to use Google's Colaboratory notebook platform for this workshop.  Colaboratory is “a Google research project created to help disseminate machine learning education and research.”  If you would like to know more about Colaboratory in general, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\r\n","\r\n","Using the Google Colaboratory platform allows us to focus on learning and writing Python in the workshop rather than on setting up Python, which can sometimes take a bit of extra work depending on platforms, operating systems, and other installed applications. If you'd like to install a Python distribution locally, though, we're happy to help. Feel free to [get help from our graduate consultants](https://www.lib.ncsu.edu/dxl) or [schedule an appointment with Libraries staff](https://go.ncsu.edu/dvs-request)."]},{"cell_type":"markdown","metadata":{"id":"diWLAlRBTsWT"},"source":["## Guided Instruction\r\n","This week we're focusing on data wrangling using Python Pandas. We're going to manipulate our dataset in order to make it more usable for answering questions about the information.\r\n","\r\n","Content Warning: This dataset contains information relating to violence towards animals. We understand that this may be distressing, and if you need to step away from the workshop we understand.\r\n","\r\n","In this section, we will work through examples using data from the [Federal Aviation Administration (FAA) Wildlife Strikes Database](https://wildlife.faa.gov/search). We have filtered the data to only include North Carolina.\r\n","\r\n","> \"The FAA Wildlife Strike Database contains records of reported wildlife strikes since 1990. Strike reporting is voluntary. Therefore, this database only represents the information we have received from airlines, airports, pilots, and other sources.\" - [FAA website](https://wildlife.faa.gov/home)"]},{"cell_type":"code","metadata":{"id":"hsS2thybwJpY"},"source":["# Import the Pandas library as pd (callable in our code as pd)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77IUEVvoNhpJ"},"source":["### Importing datasets\r\n","\r\n","We have prepared the data from the FAA website for this workshop. We will import those datasets into our notebook to use them for data analysis.\r\n","\r\n","- [Preview the CSV file (opens on GitHub)](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_1990-1999.csv) - wildlife strike data from the years 1990-1999\r\n","-[Preview the Excel file (this link will download the file)](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2000-2009.xlsx?raw=true) - wildlife strike data from the years 2000-2009\r\n","- [Preview the JSON file (opens on GitHub)](https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2010-2019.json) - wildlife strike data from the years 2010-2019"]},{"cell_type":"code","metadata":{"id":"pfCttfhqNhpS"},"source":["# Import the CSV file (wildlife strike data from the years 1990-1999)\n","csv_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_1990-1999.csv'\n","\n","\n","# Print out the first five columns of the dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NKTp-O2vNhpT"},"source":["# Import the Excel file (wildlife strike data from the years 2000-2009)\n","xls_file_url = 'https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2000-2009.xlsx?raw=true'\n","\n","\n","# Print out the first five columns of the dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DyV7h5pNhpU"},"source":["#Import the JSON file (wildlife strike data from the years 2010-2019)\n","json_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_strikes_2010-2019.json'\n","\n","\n","# Print out the first five columns of the dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZ6_a__au-7z"},"source":["### Reset DataFrame index labels\r\n","The JSON file we imported does not include the column `INDX_NR`. Instead, these values are used as the index labels. We want this dataset to match the format of our other datasets, so we first need to reset the index using the DataFrame method `reset_index()`."]},{"cell_type":"code","metadata":{"id":"NexfOR1xPRcF"},"source":["# Reset the JSON DataFrame index and rename the column\r\n","\r\n","\r\n","# Print out the first five columns of the dataset\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7rigiVVn3PpB"},"source":["### Renaming column labels\n","\n","When we reset our index a new column `index` was created. Let's change the name of this column to `INDX_NR` to match our other datasets using the DataFrame `rename()` method."]},{"cell_type":"code","metadata":{"id":"k0AUqkC2OD5v"},"source":["# Rename the column we created\r\n","\r\n","\r\n","# Print out the first five columns of the dataset\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sBKmROb2YK6_"},"source":["### Concatenate the three DataFrames\r\n","\r\n","We want to be able to work with all of the data we have imported at once, so we need to pull all three DataFrames into one. They all have the same columns now, so we can concatenate them based on columns (similar to adding them together, one on top of another) using the pandas method `concat()`. We also need to consider the current index labels for each dataset. We will create a new zero-based integer index label for the concatenated dataset by passing the keyword argument `ignore_index=True` into the `concat()` method."]},{"cell_type":"code","metadata":{"id":"sEIc3jUzYNq5"},"source":["# Concatenate all the datasets into one\r\n","\r\n","\r\n","# Print the shape (number of rows and columns) of the full DataFrame\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnEJzysJ4N2h"},"source":["### Merge DataFrames\r\n","\r\n","Our dataset includes a column of species IDs (`SPECIES_ID`) that consist of alpha-numeric codes that reference a specific species of animal. This code is not very helpful if we want to know the species name of an animal involved in a strike. Let's join our dataset with another dataset containing unique species IDs and species names using the shared column `SPECIES_ID` to generate a new column of data (`SPECIES`) containing species name using `merge()`. The URL to the dataset of species IDs and names is stored in the variable `species_names_file_url`."]},{"cell_type":"code","metadata":{"id":"gTL942qP7-so"},"source":["# Load the species ID table (stored in a CSV file)\n","species_names_file_url = 'https://raw.githubusercontent.com/NCSU-Libraries/data-viz-workshops/master/Python_Open_Labs/data/FAA_Wildlife_species_id_table.csv'\n","\n","\n","# Print the loaded species ID table\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLUpy4CaexGD"},"source":["![Left join visual example](https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/Data_wrangling_with_Pandas/left-join.png?raw=true)"]},{"cell_type":"code","metadata":{"id":"G0iqjbAUm9_9"},"source":["# Create a new DataFrame from a \"left\" join of the full dataset and the species\n","# ID table based on the shared column \"SPECIES_ID\"\n","\n","\n","# Print out the columns \"SPECIES\" and \"SPECIES_ID\" from the new merged dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GcwpUDzN34rj"},"source":["### Removing unnecessary columns\n","\n","We can reduce the size of our dataset by removing unnecessary columns of data using the DataFrame `drop()` method."]},{"cell_type":"code","metadata":{"id":"z1YZ_4pE7ZBU"},"source":["# Remove the \"STATE\", \"FAAREGION\", and \"COMMENT\" columns using \"drop()\"\"\n","\n","\n","# Print out the first five records of the DataFrame\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLMysVq9yKYX"},"source":["### Calculating new columns"]},{"cell_type":"markdown","metadata":{"id":"ZEtlT-TaHjfA"},"source":["#### Create a new column using an expression\n","\n","We may want to add a new column that is calculated based on other columns. In this example, we create a new column (`SINGLE_OR_MULTI_ENGINE`) of boolean values that tells us if the plane was a single-engine (TRUE) or a multi-engine (FALSE) plane using a comparison operator to test if the value in the column `NUM_ENGS` equals 1."]},{"cell_type":"code","metadata":{"id":"IL3zoS0cykQ8"},"source":["# Create a new column of boolean values indicating single- or multi-engine\n","\n","\n","# Print out the new column\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0etw8hbjI6QZ"},"source":["#### Create a new column using `apply()`\n","\n","Sometimes you need to create a new column based on more complex manipulation of existing data. In this example, we use the `apply()` method to apply the function `calc_hour` along the rows in the column `TIME`. The `calc_hour` function parses an integer value of the hour from a string containing the time at which a strike occurred. We create a new column `HOUR` that contains a numerical representation of the hour in which a strike occurred."]},{"cell_type":"code","metadata":{"id":"jdtZZcTdJAHg"},"source":["# Define a function that takes a time string in the form \"HH:MM\" and returns the\n","# hour as an integer if the hour value is valid\n","def calc_hour(time_str):\n","    hour = time_str.split(':')[0]\n","    if hour.strip(' ') != '':\n","        return int(hour)\n","\n","# Use the DataFrame apply() method to call calc_hour on the \"TIME\" column and\n","# create a new column \"HOUR\" in our DataFrame\n","\n","\n","# Print out the \"TIME\" and \"HOUR\" columns from our DataFrame\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2RNfRsR13Mx"},"source":["### Replace values in a column\r\n","\r\n","We can replace values in a column based on conditions, similar to \"find and replace.\" In this example, we make our new `SINGLE_OR_MULTI_ENGINE` column more descriptive by changing `True` into \" Single engine\" and `False` into \"Multi engine\".\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"TbS4YUYV17sE"},"source":["# Replace True or False values with new strings, \"Single engine\" or \"Multi engine\"\n","\n","\n","# Print out the updated column of data\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KtowpcFjYB98"},"source":["### Filtering\r\n","\r\n","We can filter our data using conditional statements. This can help us remove unecessary rows of data or observe a specific range of data."]},{"cell_type":"code","metadata":{"id":"u4lPRIIF9wKB"},"source":["# Filter the data to only see incidents that happened at night\n","\n","\n","# Print out the filtered data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TrY9dUg-YEjI"},"source":["# Filter the data to only see data from 2010 and after\n","\n","\n","# Print out the filtered data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TfhcH7Hv9-Zx"},"source":["# Filter the data to only see incidents from 2010 and after that happened at night\n","\n","\n","# Print out the filtered data\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KUnZceXrWtpC"},"source":["\r\n","\r\n","---\r\n","\r\n","\r\n","## Open work time\r\n","You can use this time to ask questions, collaborate, or work on the following activities (on your own or in a group)"]},{"cell_type":"markdown","metadata":{"id":"FAqsOIs2w89S"},"source":["### Exercise 1: Rename column headers\n","\n","Rename the column `REG` to the more descriptive `AIRCRAFT_REGISTRATION`"]},{"cell_type":"code","metadata":{"id":"kPib5An85g_f"},"source":["# Change the column name \"REG\" to \"AIRCRAFT_REGISTRATION\"\n","\n","\n","# Print out the new DataFrame columns\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oh08mPHb-0RB"},"source":["### Exercise 2: Remove unnecessary columns\n","\n","The are several columns of data that are not relevant for our analyses. Remove all columns related to engine and damage location (e.g., all the columns that begin with `ENG_`, `DAM_`, and `STR_`). A list of these column names is provided in the variable `drop_columns`.\n","\n","**Bonus:** See if you can derive the column names in the list `drop_columns` from the dataset"]},{"cell_type":"code","metadata":{"id":"y0u9pN2ggWn7"},"source":["# A list of column names to remove from the DataFrame\n","drop_columns = ['ENG_1_POS', 'ENG_2_POS', 'ENG_3_POS', 'ENG_4_POS', 'STR_RAD',\n","                'DAM_RAD', 'STR_WINDSHLD', 'DAM_WINDSHLD', 'STR_NOSE',\n","                'DAM_NOSE', 'STR_ENG1', 'DAM_ENG1', 'STR_ENG2', 'DAM_ENG2',\n","                'STR_ENG3', 'DAM_ENG3', 'STR_ENG4', 'DAM_ENG4', 'STR_PROP',\n","                'DAM_PROP', 'STR_WING_ROT', 'DAM_WING_ROT', 'STR_FUSE',\n","                'DAM_FUSE', 'STR_LG', 'DAM_LG', 'STR_TAIL', 'DAM_TAIL',\n","                'STR_LGHTS', 'DAM_LGHTS', 'STR_OTHER', 'DAM_OTHER']\n","\n","# Remove unnecessary columns\n","\n","\n","# Print out the new DataFrame columns\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8TSrmwW868c"},"source":["### Exercise 3: Filter out unnecessary rows\n","\n","Our dataset should only contain data from the years 1990-2019. Remove any rows of data that contain strikes that occurred outside of this year range."]},{"cell_type":"code","metadata":{"id":"3HbTYcuL9Xgj"},"source":["# Filter out rows of data that contain strikes that occurred outside of the year\n","# range 1990-2019\n","\n","\n","# Print out the new filtered DataFrame\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Hc8TS8Xar8O"},"source":["### Exercise 4: Join airline operator names with the full dataset\r\n","\r\n","Our dataset contains a column of airline operator IDs (`OPID`). These IDs correspond with airline operator names (e.g., Delta Airlines, Military, United Airlines, etc.). We have another dataset that contains arline operator IDs (in a column named `OPID`) and the corresponding airline operator name (in a column named `OPERATOR`). The URL to this dataset is stored in the variable `op_name_file_url`. Load this dataset and use a left join to merge the operator name with the full dataset."]},{"cell_type":"code","metadata":{"id":"iSQmchxx-BFU"},"source":["# URL to the CSV file containing unique airline operator IDs and names\n","op_name_file_url = 'https://github.com/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/data/FAA_Wildlife_operator_id_table.csv?raw=true'\n","\n","# Load the operator ID and name dataset into a DataFrame\n","\n","\n","# Join airline operator names to the full dataset using matching operater IDs\n","\n","\n","# Print out the columns \"OPID\" and \"OPERATOR\" from the new merged DataFrame\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"etgjBVCQoGWv"},"source":["### Exercise 5: Create a new column containing month names\n","\n","Our dataset currently contains a column of integer values representing the month number in which a strike occurred (1-12). It would be helpful to have a column containing the month name (e.g., January, February, etc.). Calculate a new column labeled `MONTH_NAME` containing the month name in which a stike occurred.\n","\n","**TIP:** There are multiple ways you could consider creating this new column (e.g., using `replace()` or `apply()`), but it might be helpful to have a way to map month numbers (1-12) to month names (January - December) (e.g., a list or dictionary)."]},{"cell_type":"code","metadata":{"id":"i1ti8X6sYLvM"},"source":["# Create a new column \"MONTH_NAME\" containing month names in which a strike occurred\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_dY4wqNdRSD"},"source":["## Further resources\r\n","\r\n","### Filled version of this notebook\r\n","\r\n","[Python Open Labs Week 2 filled notebook](https://colab.research.google.com/github/NCSU-Libraries/data-viz-workshops/blob/master/Python_Open_Labs/Data_wrangling_with_Pandas/Python_Open_Labs_Week2_filled.ipynb) - a version of this notebook with all code filled in for the guided activity and exercises.\r\n","\r\n","### Learning resources\r\n","\r\n","- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html) - a free, online version of Jake VanderPlas' introduction to data science with Python, includes a chapter on data manipulation with pandas.\r\n","- [Python Programming for Data Science](https://www.tomasbeuzen.com/python-programming-for-data-science/README.html) - a website providing a great overview of conducting data science with Python including pandas.\r\n","\r\n","### Finding help with pandas\r\n","\r\n","The [Pandas website](https://pandas.pydata.org/) and [online documentation](http://pandas.pydata.org/pandas-docs/stable/) are useful resources, and of course the indispensible [Stack Overflow has a \"pandas\" tag](https://stackoverflow.com/questions/tagged/pandas).  There is also a (much younger, much smaller) [sister site dedicated to Data Science questions that has a \"pandas\" tag](https://datascience.stackexchange.com/questions/tagged/pandas) too."]},{"cell_type":"markdown","metadata":{"id":"MAAF-mLyRqeE"},"source":["## Evaluation Survey\r\n","Please, spend 1 minute answering these questions that help improve future workshops.\r\n","\r\n","https://go.ncsu.edu/dvs-eval"]},{"cell_type":"markdown","metadata":{"id":"i6Sj-7OYR5JL"},"source":["## Credits\r\n","\r\n","This workshop was created by Walt Gurley and Claire Cahoon, adapted from previous workshop materials by Scott Bailey and Simon Wiles, of Stanford Libraries."]}]}