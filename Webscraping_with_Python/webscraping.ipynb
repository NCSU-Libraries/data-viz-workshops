{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bited2af9defb114361a345112ec36e2c37",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Webscraping with Python\n",
    "\n",
    "## Instructors\n",
    "\n",
    "- Scott Bailey\n",
    "- Claire Cahoon\n",
    "- Walt Gurley\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of our workshop today, we hope you'll have a sense of when and why to webscrape, and how to extract select information from websites into useable data.  \n",
    "\n",
    "## Topics\n",
    "\n",
    "- what is webscraping?\n",
    "- ethical and legal issues in webscraping\n",
    "- html and css\n",
    "- webscraping with requests-html\n",
    "\n",
    "##  Setup\n",
    "\n",
    "With this Google Colab notebook open, click the \"Copy to Drive\" button that appears in the menu bar. The notebook will then be attached to your own user account, so you can edit it in any way you like -- you can even take notes directly in the notebook.\n",
    "\n",
    "## Zoom etiquette\n",
    "\n",
    "Please make sure that your mic is muted during the workshop.\n",
    "\n",
    "## Questions during the workshop\n",
    "\n",
    "During the workshop, we have a second instructor who will be monitoring chat on Zoom. Please feel free to ask questions by chat throughout the workshop. Our second instructor will answer as able, and will aggregate questions with answers that might help everyone. \n",
    "\n",
    "At the end of each section of the workshop, the primary instructor will answer aggregated and new questions as time permits. If we aren't able to get to your question during the workshop, please follow up with us afterward. \n",
    "\n",
    "## Jupyter Notebooks and Google Colaboratory\n",
    "\n",
    "Jupyter notebooks are a way to write and run Python code in an interactive way. They're quickly becoming a standard way of putting together data, code, and written explanations or visualizations into a single document and sharing that. There are a lot of ways that you can run Jupyter notebooks, including just locally on your computer, but we've decided to use Google's Colaboratory notebook platform for this workshop.  Colaboratory is “a Google research project created to help disseminate machine learning education and research.”  If you would like to know more about Colaboratory in general, you can visit the [Welcome Notebook](https://colab.research.google.com/notebooks/welcome.ipynb).\n",
    "\n",
    "Using the Google Colaboratory platform allows us to focus on learning and writing Python in the workshop rather than on setting up Python, which can sometimes take a bit of extra work depending on platforms, operating systems, and other installed applications. If you'd like to install a Python distribution locally, though, we're happy to help. Feel free to drop by our walk-in consulting or schedule an appointment with us.\n",
    "\n",
    "https://go.ncsu.edu/dvs-request\n",
    "\n",
    "\n",
    "## Environment\n",
    "If you would prefer to use Anaconda or your own local installation of Python or Jupyter Notebooks, for this workshop you will need an environment with the following packages installed and available:\n",
    "- `pandas`\n",
    "- `requests-html`\n",
    "\n",
    "Please note that we will likely not have time during the workshop to support you with problems related to a local environment, and we do recommend using the Colaboratory notebooks if you are at all unsure.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## What is webscraping?\n",
    "\n",
    "**Question**: what types of tasks do you think of as webscraping?\n",
    "\n",
    "Webscraping is the selective retrieval of information from HTML documents on the web. Expansively, we could include the process of directed, automated retrieval of other filetypes such as PDF and CSV from web servers. \n",
    "\n",
    "Webcrawling is the automated indexing of websites, and typically involves progressive processing of a site and its links, and the repetition of this process.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Ethical concerns in webscraping\n",
    "\n",
    "First: ethics is not law, but you should be concerned with both. The legality of different types and situations in webscraping continues to be debated and decided. \n",
    "\n",
    "There are at least two things you need to check before starting to scrape a website. \n",
    "\n",
    "1. Is the content under copyright or licensed in such a way that you should not scrape it? Are there terms of service that limit your use of the site and/or its content?\n",
    "2. Does the site have a robots.txt file that circumscribes what a robot/scraper should do on the site?\n",
    "\n",
    "Further considerations:\n",
    "- **How you scrape**: Is your webscraping going to negatively impact the site, especially due to frequency of requests? Are you identifying yourself in a header when you scrape? Are you publishing your code or redistributing that? Be good citizens of the web.\n",
    "- **What you do with the data**: Are you giving correct attribution? Are you illegally or unethically redistributing content or data? \n",
    "\n",
    "There are plenty of resources online about law, ethics, and best practices around webscraping. Here are a small few further resources if you'd like to think further about these concerns:\n",
    " \n",
    "- https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01\n",
    "- https://gijn.org/2015/08/12/on-the-ethics-of-web-scraping-and-data-journalism/\n",
    "- https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/\n",
    "\n",
    "**Notice: I am not offering you legal advice on whether to scrape or not or what to scrape, just mentioning issues for consideration.**\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Common webscraping libraries\n",
    "\n",
    "There are hundreds of tutorials online about webscraping with Python, of varying quality. \n",
    "\n",
    "- selenium\n",
    "- scrapy\n",
    "- beautifulsoup\n",
    "- requests\n",
    "- urllib\n",
    "- mechanicalsoup\n",
    "- requests-html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Webscraping with requests-html\n",
    "\n",
    "Why requests-html?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Further topics:\n",
    "\n",
    "- headless browsers\n",
    "- dynamic websites with Javascript"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}